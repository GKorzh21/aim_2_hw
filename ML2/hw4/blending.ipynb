{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2dfa3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, TargetEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "# Загрузка данных\n",
    "train = pd.read_csv('train_contest.csv')\n",
    "test = pd.read_csv('test_contest.csv')\n",
    "features = list(train.drop('target', axis=1).columns)\n",
    "cat_features = train.select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea9158b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode_data(train_df, test_df, cat_features):\n",
    "    le = LabelEncoder()\n",
    "    for feat in cat_features:\n",
    "        combined = pd.concat([train_df[feat], test_df[feat]], axis=0)\n",
    "        le.fit(combined)\n",
    "        train_df[feat] = le.transform(train_df[feat])\n",
    "        test_df[feat] = le.transform(test_df[feat])\n",
    "    return train_df, test_df\n",
    "\n",
    "# Применяем Label Encoding\n",
    "train, test = label_encode_data(train, test, cat_features)\n",
    "\n",
    "# Разделение данных для валидации\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train[features], train['target'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Функции для обучения отдельных моделей\n",
    "def train_lightgbm(X_train, y_train, X_val, y_val, params):\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    \n",
    "    # Callback для ранней остановки\n",
    "    callbacks = [\n",
    "        lgb.early_stopping(stopping_rounds=50, verbose=False),\n",
    "        lgb.log_evaluation(period=0)  # Отключаем логирование\n",
    "    ]\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[val_data],\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_xgboost(X_train, y_train, X_val, y_val, params):\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    # Callback для ранней остановки\n",
    "    watchlist = [(dval, 'eval')]\n",
    "    \n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        evals=watchlist,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_catboost(X_train, y_train, X_val, y_val, params):\n",
    "    # Callback для CatBoost (уже встроен в метод fit)\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=(X_val, y_val),\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_catboost(X_train, y_train, X_val, y_val, params):\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=(X_val, y_val),\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_random_forest(X_train, y_train, params):\n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_ridge(X_train, y_train, params):\n",
    "    model = Ridge(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Функции для оптимизации гиперпараметров с помощью Optuna\n",
    "def optimize_lightgbm(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    model = train_lightgbm(X_train, y_train, X_val, y_val, params)\n",
    "    preds = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))  # Вместо squared=False вычисляем корень вручную\n",
    "    return rmse\n",
    "\n",
    "def optimize_xgboost(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'eta': trial.suggest_float('eta', 0.001, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),\n",
    "    }\n",
    "    \n",
    "    model = train_xgboost(X_train, y_train, X_val, y_val, params)\n",
    "    preds = model.predict(xgb.DMatrix(X_val))\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    return rmse\n",
    "\n",
    "def optimize_catboost(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'random_strength': trial.suggest_int('random_strength', 0, 100),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 10.0),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-5, 10.0, log=True),\n",
    "        'verbose': False\n",
    "    }\n",
    "    \n",
    "    model = train_catboost(X_train, y_train, X_val, y_val, params)\n",
    "    preds = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    return rmse\n",
    "\n",
    "# Оптимизация моделей\n",
    "def optimize_models():\n",
    "    study_lgb = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "    study_lgb.optimize(optimize_lightgbm, n_trials=20, show_progress_bar=True)\n",
    "    \n",
    "    study_xgb = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "    study_xgb.optimize(optimize_xgboost, n_trials=20, show_progress_bar=True)\n",
    "    \n",
    "    study_cb = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "    study_cb.optimize(optimize_catboost, n_trials=20, show_progress_bar=True)\n",
    "    \n",
    "    return {\n",
    "        'lightgbm': study_lgb.best_params,\n",
    "        'xgboost': study_xgb.best_params,\n",
    "        'catboost': study_cb.best_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c06487e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-03 20:19:00,482] A new study created in memory with name: no-name-e4e510ad-84e5-4187-ac1f-fe4635202f3a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a389d1224d44d6b873390232d84cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-05-03 20:19:01,179] Trial 0 finished with value: 1879.5804103577336 and parameters: {'num_leaves': 74, 'learning_rate': 0.09332547107715061, 'feature_fraction': 0.7607356733695185, 'bagging_fraction': 0.8698128628524322, 'bagging_freq': 4, 'min_child_samples': 96}. Best is trial 0 with value: 1879.5804103577336.\n",
      "[I 2025-05-03 20:19:02,267] Trial 1 finished with value: 1892.7005896165106 and parameters: {'num_leaves': 209, 'learning_rate': 0.07205300652931702, 'feature_fraction': 0.9926484125049213, 'bagging_fraction': 0.6510508288691708, 'bagging_freq': 3, 'min_child_samples': 44}. Best is trial 0 with value: 1879.5804103577336.\n",
      "[I 2025-05-03 20:19:03,106] Trial 2 finished with value: 1887.82630461998 and parameters: {'num_leaves': 175, 'learning_rate': 0.054256690027979934, 'feature_fraction': 0.8027060485917454, 'bagging_fraction': 0.409343259958572, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 0 with value: 1879.5804103577336.\n",
      "[I 2025-05-03 20:19:04,029] Trial 3 finished with value: 1878.322162553047 and parameters: {'num_leaves': 141, 'learning_rate': 0.061597146910113545, 'feature_fraction': 0.46896433764825934, 'bagging_fraction': 0.8422558824606481, 'bagging_freq': 2, 'min_child_samples': 64}. Best is trial 3 with value: 1878.322162553047.\n",
      "[I 2025-05-03 20:19:05,183] Trial 4 finished with value: 1895.4744714237506 and parameters: {'num_leaves': 270, 'learning_rate': 0.03973028315742655, 'feature_fraction': 0.5979669976648461, 'bagging_fraction': 0.873437753644257, 'bagging_freq': 2, 'min_child_samples': 75}. Best is trial 3 with value: 1878.322162553047.\n",
      "[I 2025-05-03 20:19:06,251] Trial 5 finished with value: 1900.2034269431465 and parameters: {'num_leaves': 254, 'learning_rate': 0.03951488930983143, 'feature_fraction': 0.7352034674452061, 'bagging_fraction': 0.6533220397020233, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 3 with value: 1878.322162553047.\n",
      "[I 2025-05-03 20:19:07,036] Trial 6 finished with value: 1911.2280289277178 and parameters: {'num_leaves': 139, 'learning_rate': 0.036594677794981496, 'feature_fraction': 0.4096444436919209, 'bagging_fraction': 0.5942994899954704, 'bagging_freq': 2, 'min_child_samples': 87}. Best is trial 3 with value: 1878.322162553047.\n",
      "[I 2025-05-03 20:19:08,162] Trial 7 finished with value: 1891.0312413545712 and parameters: {'num_leaves': 253, 'learning_rate': 0.07888110998693057, 'feature_fraction': 0.9889090402004965, 'bagging_fraction': 0.6257457412782292, 'bagging_freq': 7, 'min_child_samples': 74}. Best is trial 3 with value: 1878.322162553047.\n",
      "[I 2025-05-03 20:19:09,140] Trial 8 finished with value: 1889.1299641631133 and parameters: {'num_leaves': 198, 'learning_rate': 0.05365030827116447, 'feature_fraction': 0.694014289140701, 'bagging_fraction': 0.4352900818642948, 'bagging_freq': 6, 'min_child_samples': 62}. Best is trial 3 with value: 1878.322162553047.\n",
      "[I 2025-05-03 20:19:09,610] Trial 9 finished with value: 1892.810765321768 and parameters: {'num_leaves': 40, 'learning_rate': 0.07579441227320906, 'feature_fraction': 0.7391502450523586, 'bagging_fraction': 0.5611931068752688, 'bagging_freq': 7, 'min_child_samples': 32}. Best is trial 3 with value: 1878.322162553047.\n",
      "[I 2025-05-03 20:19:10,371] Trial 10 finished with value: 2536.2512207312743 and parameters: {'num_leaves': 106, 'learning_rate': 0.003702397352934768, 'feature_fraction': 0.4163396916350818, 'bagging_fraction': 0.9595014428350929, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 3 with value: 1878.322162553047.\n",
      "[I 2025-05-03 20:19:11,070] Trial 11 finished with value: 1877.8171815684461 and parameters: {'num_leaves': 68, 'learning_rate': 0.09872569924729874, 'feature_fraction': 0.5502452888941994, 'bagging_fraction': 0.8190959934498075, 'bagging_freq': 5, 'min_child_samples': 98}. Best is trial 11 with value: 1877.8171815684461.\n",
      "[I 2025-05-03 20:19:11,666] Trial 12 finished with value: 1888.2735564374495 and parameters: {'num_leaves': 31, 'learning_rate': 0.0991549153456107, 'feature_fraction': 0.5322425673253112, 'bagging_fraction': 0.7840659662257201, 'bagging_freq': 5, 'min_child_samples': 60}. Best is trial 11 with value: 1877.8171815684461.\n",
      "[I 2025-05-03 20:19:12,486] Trial 13 finished with value: 2052.6829972821524 and parameters: {'num_leaves': 106, 'learning_rate': 0.015803067798363032, 'feature_fraction': 0.5230182379038861, 'bagging_fraction': 0.7742192463853588, 'bagging_freq': 5, 'min_child_samples': 98}. Best is trial 11 with value: 1877.8171815684461.\n",
      "[I 2025-05-03 20:19:13,385] Trial 14 finished with value: 1878.325236562426 and parameters: {'num_leaves': 117, 'learning_rate': 0.06438503446566869, 'feature_fraction': 0.5248674927186121, 'bagging_fraction': 0.992480210577435, 'bagging_freq': 5, 'min_child_samples': 69}. Best is trial 11 with value: 1877.8171815684461.\n",
      "[I 2025-05-03 20:19:13,989] Trial 15 finished with value: 1881.9314220155256 and parameters: {'num_leaves': 67, 'learning_rate': 0.08326938900426076, 'feature_fraction': 0.6370402385366996, 'bagging_fraction': 0.763973934983142, 'bagging_freq': 1, 'min_child_samples': 85}. Best is trial 11 with value: 1877.8171815684461.\n",
      "[I 2025-05-03 20:19:14,934] Trial 16 finished with value: 1877.3427505704863 and parameters: {'num_leaves': 154, 'learning_rate': 0.08979370057184564, 'feature_fraction': 0.4744048665711693, 'bagging_fraction': 0.882986789139299, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 16 with value: 1877.3427505704863.\n",
      "[I 2025-05-03 20:19:16,173] Trial 17 finished with value: 1892.8586503239667 and parameters: {'num_leaves': 300, 'learning_rate': 0.08945804106054633, 'feature_fraction': 0.6110197426725439, 'bagging_fraction': 0.9239154014846169, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 16 with value: 1877.3427505704863.\n",
      "[I 2025-05-03 20:19:16,816] Trial 18 finished with value: 1883.9240811393652 and parameters: {'num_leaves': 70, 'learning_rate': 0.09852047379162987, 'feature_fraction': 0.4683352441152131, 'bagging_fraction': 0.723816572766088, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 16 with value: 1877.3427505704863.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-03 20:19:17,797] A new study created in memory with name: no-name-f2639e0c-023f-4555-a277-1b50543c537d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-05-03 20:19:17,796] Trial 19 finished with value: 1886.5404947185018 and parameters: {'num_leaves': 188, 'learning_rate': 0.0841008743805426, 'feature_fraction': 0.8499679229087533, 'bagging_fraction': 0.830208985162429, 'bagging_freq': 6, 'min_child_samples': 52}. Best is trial 16 with value: 1877.3427505704863.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2780ed4f60472386b491d3293403dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-05-03 20:19:18,131] Trial 0 finished with value: 2553.942292171551 and parameters: {'eta': 0.03218689825159262, 'max_depth': 9, 'subsample': 0.6869183440303537, 'colsample_bytree': 0.5658856552042141, 'lambda': 0.0020198586734529265, 'alpha': 0.011869952752399835}. Best is trial 0 with value: 2553.942292171551.\n",
      "[I 2025-05-03 20:19:18,447] Trial 1 finished with value: 2218.115208904397 and parameters: {'eta': 0.08452061955641244, 'max_depth': 9, 'subsample': 0.7665154696414427, 'colsample_bytree': 0.8801792188768286, 'lambda': 0.0023798714846240696, 'alpha': 1.1055089718149416}. Best is trial 1 with value: 2218.115208904397.\n",
      "[I 2025-05-03 20:19:18,721] Trial 2 finished with value: 2662.439901854962 and parameters: {'eta': 0.02014894027101138, 'max_depth': 7, 'subsample': 0.9316496018689759, 'colsample_bytree': 0.8829073240294543, 'lambda': 0.04606104112984548, 'alpha': 0.18606429819288478}. Best is trial 1 with value: 2218.115208904397.\n",
      "[I 2025-05-03 20:19:18,976] Trial 3 finished with value: 2362.1091412099668 and parameters: {'eta': 0.07555374330351394, 'max_depth': 5, 'subsample': 0.8391802748152253, 'colsample_bytree': 0.5985870876062194, 'lambda': 5.51521547947684, 'alpha': 0.004141031156511166}. Best is trial 1 with value: 2218.115208904397.\n",
      "[I 2025-05-03 20:19:19,248] Trial 4 finished with value: 2800.8502784991524 and parameters: {'eta': 0.006795080050796405, 'max_depth': 7, 'subsample': 0.8476965361430056, 'colsample_bytree': 0.8560271274693694, 'lambda': 0.1901306468871308, 'alpha': 0.08843082155878225}. Best is trial 1 with value: 2218.115208904397.\n",
      "[I 2025-05-03 20:19:19,565] Trial 5 finished with value: 2717.500562794444 and parameters: {'eta': 0.014008794342647783, 'max_depth': 10, 'subsample': 0.5081004616666898, 'colsample_bytree': 0.6903603761798554, 'lambda': 0.07441048845584528, 'alpha': 7.154966978323126}. Best is trial 1 with value: 2218.115208904397.\n",
      "[I 2025-05-03 20:19:19,825] Trial 6 finished with value: 2653.9073084866054 and parameters: {'eta': 0.024935266227436175, 'max_depth': 5, 'subsample': 0.5514273908397194, 'colsample_bytree': 0.7316636575586737, 'lambda': 0.0018309087150246933, 'alpha': 0.4702776294191066}. Best is trial 1 with value: 2218.115208904397.\n",
      "[I 2025-05-03 20:19:20,100] Trial 7 finished with value: 2291.922137844227 and parameters: {'eta': 0.07647027649378911, 'max_depth': 8, 'subsample': 0.5181991132515016, 'colsample_bytree': 0.6023645324741238, 'lambda': 0.00160497524107039, 'alpha': 0.8934446365974152}. Best is trial 1 with value: 2218.115208904397.\n",
      "[I 2025-05-03 20:19:20,364] Trial 8 finished with value: 2832.6774911150305 and parameters: {'eta': 0.004717283977036985, 'max_depth': 5, 'subsample': 0.7058230803964751, 'colsample_bytree': 0.7225808449332785, 'lambda': 6.124951783678547, 'alpha': 1.14538972125533}. Best is trial 1 with value: 2218.115208904397.\n",
      "[I 2025-05-03 20:19:20,661] Trial 9 finished with value: 2416.312664565934 and parameters: {'eta': 0.05131783480611975, 'max_depth': 9, 'subsample': 0.8537228817320055, 'colsample_bytree': 0.5953257417486505, 'lambda': 0.5751338135446871, 'alpha': 0.8296514171134777}. Best is trial 1 with value: 2218.115208904397.\n",
      "[I 2025-05-03 20:19:20,921] Trial 10 finished with value: 2383.1126429393826 and parameters: {'eta': 0.09517261308508679, 'max_depth': 3, 'subsample': 0.6323994965686837, 'colsample_bytree': 0.9840127448148365, 'lambda': 0.01282955074134757, 'alpha': 6.438552433787021}. Best is trial 1 with value: 2218.115208904397.\n",
      "[I 2025-05-03 20:19:21,232] Trial 11 finished with value: 2301.03422275106 and parameters: {'eta': 0.075086069261118, 'max_depth': 8, 'subsample': 0.7723118866729435, 'colsample_bytree': 0.5061324709769561, 'lambda': 0.0010627797023687656, 'alpha': 0.03408888181184733}. Best is trial 1 with value: 2218.115208904397.\n",
      "[I 2025-05-03 20:19:21,580] Trial 12 finished with value: 2158.7718947399367 and parameters: {'eta': 0.09912149606300165, 'max_depth': 10, 'subsample': 0.5967015000716913, 'colsample_bytree': 0.8279516635333922, 'lambda': 0.008768673263651364, 'alpha': 2.005183804047696}. Best is trial 12 with value: 2158.7718947399367.\n",
      "[I 2025-05-03 20:19:21,922] Trial 13 finished with value: 2147.871484834316 and parameters: {'eta': 0.09821048433059099, 'max_depth': 10, 'subsample': 0.6321587545314572, 'colsample_bytree': 0.8427767055935231, 'lambda': 0.008577321364336848, 'alpha': 2.6783047348660873}. Best is trial 13 with value: 2147.871484834316.\n",
      "[I 2025-05-03 20:19:22,268] Trial 14 finished with value: 2158.124138571666 and parameters: {'eta': 0.09986103636058254, 'max_depth': 10, 'subsample': 0.6035017297893286, 'colsample_bytree': 0.8108814073948458, 'lambda': 0.012008682087249138, 'alpha': 4.782277209912297}. Best is trial 13 with value: 2147.871484834316.\n",
      "[I 2025-05-03 20:19:22,610] Trial 15 finished with value: 2383.0779230540143 and parameters: {'eta': 0.0512260004209775, 'max_depth': 10, 'subsample': 0.6327822061789451, 'colsample_bytree': 0.7887207954672653, 'lambda': 0.01207779113471166, 'alpha': 3.6664270522097704}. Best is trial 13 with value: 2147.871484834316.\n",
      "[I 2025-05-03 20:19:22,908] Trial 16 finished with value: 2321.7176529199965 and parameters: {'eta': 0.06655622991961238, 'max_depth': 8, 'subsample': 0.5871540278362681, 'colsample_bytree': 0.956420603585334, 'lambda': 0.028721258457156375, 'alpha': 0.0014817741852562855}. Best is trial 13 with value: 2147.871484834316.\n",
      "[I 2025-05-03 20:19:23,183] Trial 17 finished with value: 2275.983469831999 and parameters: {'eta': 0.0872213667038551, 'max_depth': 6, 'subsample': 0.673827764790861, 'colsample_bytree': 0.9416146135067229, 'lambda': 0.32631991415101536, 'alpha': 0.21345064923977233}. Best is trial 13 with value: 2147.871484834316.\n",
      "[I 2025-05-03 20:19:23,453] Trial 18 finished with value: 2496.925592583238 and parameters: {'eta': 0.061522663294764815, 'max_depth': 3, 'subsample': 0.7297317482286934, 'colsample_bytree': 0.7866513721897367, 'lambda': 0.006326702814274846, 'alpha': 8.872920625563312}. Best is trial 13 with value: 2147.871484834316.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-03 20:19:23,801] A new study created in memory with name: no-name-c331dacb-be65-4dec-9f73-5bf217d7c7d8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-05-03 20:19:23,800] Trial 19 finished with value: 2507.002420853856 and parameters: {'eta': 0.037267753153581204, 'max_depth': 10, 'subsample': 0.6392707031578031, 'colsample_bytree': 0.6712645304088417, 'lambda': 1.228582413162995, 'alpha': 2.4036270903479866}. Best is trial 13 with value: 2147.871484834316.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe221edd51314337a1b4943b7c0c0314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-05-03 20:19:29,811] Trial 0 finished with value: 1872.94472227954 and parameters: {'iterations': 841, 'depth': 8, 'learning_rate': 0.0928695543907521, 'random_strength': 36, 'bagging_temperature': 7.955910895995565, 'l2_leaf_reg': 0.004428900503354116}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:19:33,424] Trial 1 finished with value: 1876.7813740673662 and parameters: {'iterations': 546, 'depth': 6, 'learning_rate': 0.09979307652099334, 'random_strength': 26, 'bagging_temperature': 3.8792170783994417, 'l2_leaf_reg': 0.0011850144813360317}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:19:41,334] Trial 2 finished with value: 1877.4140694911298 and parameters: {'iterations': 734, 'depth': 8, 'learning_rate': 0.04913549193636657, 'random_strength': 27, 'bagging_temperature': 9.308723265212034, 'l2_leaf_reg': 4.6259003749861795e-05}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:19:54,103] Trial 3 finished with value: 1980.1124498658053 and parameters: {'iterations': 385, 'depth': 10, 'learning_rate': 0.02669249114790543, 'random_strength': 32, 'bagging_temperature': 3.7313289813143937, 'l2_leaf_reg': 5.343427504344518}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:19:59,702] Trial 4 finished with value: 1883.7914286944613 and parameters: {'iterations': 509, 'depth': 8, 'learning_rate': 0.05827523178617698, 'random_strength': 34, 'bagging_temperature': 8.03339190618631, 'l2_leaf_reg': 0.7105841168531849}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:20:10,108] Trial 5 finished with value: 1877.78894512561 and parameters: {'iterations': 683, 'depth': 9, 'learning_rate': 0.06568068508591676, 'random_strength': 85, 'bagging_temperature': 8.102704924771434, 'l2_leaf_reg': 0.0008738531915280205}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:20:15,704] Trial 6 finished with value: 2053.3007265274596 and parameters: {'iterations': 164, 'depth': 10, 'learning_rate': 0.03822255036281521, 'random_strength': 89, 'bagging_temperature': 1.4287923340732844, 'l2_leaf_reg': 0.03107071290947655}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:20:21,647] Trial 7 finished with value: 1909.9802202004619 and parameters: {'iterations': 535, 'depth': 8, 'learning_rate': 0.024731268935809177, 'random_strength': 6, 'bagging_temperature': 4.449170144614865, 'l2_leaf_reg': 0.00016188143500312234}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:20:23,981] Trial 8 finished with value: 1957.5251998327806 and parameters: {'iterations': 346, 'depth': 6, 'learning_rate': 0.047464697063475864, 'random_strength': 61, 'bagging_temperature': 6.023760191709524, 'l2_leaf_reg': 0.3628932836531768}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:20:26,431] Trial 9 finished with value: 2067.5825485863834 and parameters: {'iterations': 428, 'depth': 5, 'learning_rate': 0.021762748966635777, 'random_strength': 42, 'bagging_temperature': 9.67569399921851, 'l2_leaf_reg': 9.743852365343553}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:20:31,152] Trial 10 finished with value: 1895.3574325084933 and parameters: {'iterations': 993, 'depth': 4, 'learning_rate': 0.0995986531385578, 'random_strength': 59, 'bagging_temperature': 6.324972694129528, 'l2_leaf_reg': 0.015699801698679374}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:20:36,506] Trial 11 finished with value: 1889.5364032987586 and parameters: {'iterations': 910, 'depth': 6, 'learning_rate': 0.09574293455454702, 'random_strength': 10, 'bagging_temperature': 2.318741893704601, 'l2_leaf_reg': 0.0015667771605427502}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:20:40,870] Trial 12 finished with value: 1882.4294829739608 and parameters: {'iterations': 716, 'depth': 7, 'learning_rate': 0.08158001068748597, 'random_strength': 19, 'bagging_temperature': 3.1465937592924864, 'l2_leaf_reg': 0.001728464977509124}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:20:46,428] Trial 13 finished with value: 1880.2503497476216 and parameters: {'iterations': 830, 'depth': 6, 'learning_rate': 0.07875038550657658, 'random_strength': 50, 'bagging_temperature': 0.2005566400321923, 'l2_leaf_reg': 1.1010210030521457e-05}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:20:51,907] Trial 14 finished with value: 1876.9377280273368 and parameters: {'iterations': 656, 'depth': 7, 'learning_rate': 0.08504565467624714, 'random_strength': 66, 'bagging_temperature': 6.246210943820129, 'l2_leaf_reg': 0.0887774738065595}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:20:52,721] Trial 15 finished with value: 2042.626506807716 and parameters: {'iterations': 150, 'depth': 4, 'learning_rate': 0.06955850135046773, 'random_strength': 19, 'bagging_temperature': 5.100918785266355, 'l2_leaf_reg': 0.004236009394194981}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:20:57,287] Trial 16 finished with value: 2094.7403099522435 and parameters: {'iterations': 833, 'depth': 5, 'learning_rate': 0.00933018898542401, 'random_strength': 43, 'bagging_temperature': 7.7937336817381295, 'l2_leaf_reg': 0.00028046274054725225}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:21:02,003] Trial 17 finished with value: 1877.7511023728398 and parameters: {'iterations': 298, 'depth': 9, 'learning_rate': 0.08919372825932176, 'random_strength': 0, 'bagging_temperature': 5.10364316736836, 'l2_leaf_reg': 0.012045286941131198}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:21:07,101] Trial 18 finished with value: 1879.0405413947885 and parameters: {'iterations': 605, 'depth': 7, 'learning_rate': 0.07185644857538462, 'random_strength': 70, 'bagging_temperature': 6.91420301183481, 'l2_leaf_reg': 0.0002454934966459542}. Best is trial 0 with value: 1872.94472227954.\n",
      "[I 2025-05-03 20:21:11,510] Trial 19 finished with value: 1878.9195421238462 and parameters: {'iterations': 801, 'depth': 5, 'learning_rate': 0.09136517322524453, 'random_strength': 22, 'bagging_temperature': 2.892739926107512, 'l2_leaf_reg': 0.06958737867867378}. Best is trial 0 with value: 1872.94472227954.\n",
      "Blending completed and predictions saved to test_blended.csv\n"
     ]
    }
   ],
   "source": [
    "# Получаем оптимальные параметры\n",
    "best_params = optimize_models()\n",
    "\n",
    "# Добавляем фиксированные параметры для каждого алгоритма\n",
    "best_params['lightgbm'].update({\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'verbose': -1\n",
    "})\n",
    "\n",
    "best_params['xgboost'].update({\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'\n",
    "})\n",
    "\n",
    "best_params['catboost'].update({\n",
    "    'loss_function': 'RMSE',\n",
    "    'verbose': False\n",
    "})\n",
    "\n",
    "# Обучение моделей с лучшими параметрами на всех данных\n",
    "def train_all_models(X, y, params):\n",
    "    models = {}\n",
    "    \n",
    "    # LightGBM\n",
    "    lgb_params = params['lightgbm'].copy()\n",
    "    lgb_params['verbose'] = -1\n",
    "    models['lightgbm'] = train_lightgbm(X, y, X_val, y_val, lgb_params)\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb_params = params['xgboost'].copy()\n",
    "    models['xgboost'] = train_xgboost(X, y, X_val, y_val, xgb_params)\n",
    "    \n",
    "    # CatBoost\n",
    "    cb_params = params['catboost'].copy()\n",
    "    cb_params['verbose'] = False\n",
    "    models['catboost'] = train_catboost(X, y, X_val, y_val, cb_params)\n",
    "    \n",
    "    # Random Forest (без оптимизации для примера)\n",
    "    rf_params = {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    models['random_forest'] = train_random_forest(X, y, rf_params)\n",
    "    \n",
    "    # Ridge Regression (без оптимизации для примера)\n",
    "    ridge_params = {\n",
    "        'alpha': 1.0,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    models['ridge'] = train_ridge(X, y, ridge_params)\n",
    "    \n",
    "    return models\n",
    "\n",
    "# Обучение всех моделей\n",
    "models = train_all_models(train[features], train['target'], best_params)\n",
    "\n",
    "# Получение предсказаний от всех моделей\n",
    "def get_predictions(models, X):\n",
    "    predictions = {}\n",
    "    for name, model in models.items():\n",
    "        if name == 'xgboost':\n",
    "            predictions[name] = model.predict(xgb.DMatrix(X))\n",
    "        else:\n",
    "            predictions[name] = model.predict(X)\n",
    "    return predictions\n",
    "\n",
    "# Блендинг предсказаний (простое усреднение)\n",
    "def blend_predictions(predictions):\n",
    "    return np.mean(np.array(list(predictions.values())), axis=0)\n",
    "\n",
    "# Получаем предсказания на тестовых данных\n",
    "test_predictions = get_predictions(models, test[features])\n",
    "test['target'] = blend_predictions(test_predictions)\n",
    "\n",
    "# Сохраняем результаты\n",
    "test[['index', 'target']].to_csv('test_blended.csv', index=False)\n",
    "\n",
    "print(\"Blending completed and predictions saved to test_blended.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5004ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
