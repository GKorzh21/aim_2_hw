{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c2d3475",
   "metadata": {},
   "source": [
    "# Дорогой дневник"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e3f73",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8676fd",
   "metadata": {},
   "source": [
    "1) Сначала я решил попробовать без генерации новых фичей и без подкрутки параметров запустить LightGBM и посмотреть, что будет. Скор 0.720\n",
    "При этом пока еще нет ни генерации новых признаков, ни использования таблицы поиска и тд. Попробуем добавить.\n",
    "\n",
    "2) Просто запускаем код из \"baseline_1_pandas.ipynb\" и получаем обещаный скор 0.817\n",
    "\n",
    "3) Оптюнил 10 минут, безрезультатно. Буду придумывать новые признаки. Думаю начать с кластеризации и knn. \n",
    "\n",
    "4) Сначала решил просто расширить плавающее окно с 4 до 5 месяцев, результат 0.8192.\n",
    "\n",
    "    Есть огромное количество идей, только что заменил пандас на поларс, потому что он реально на порядок быстрее. В первую очередь хочется применить знания с семинара по интерпретации бустингов, но сначала заменить катбуст на lgbm, ибо Илья утверждал, что при должном обращении он рвет и мечет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dcb1b5",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b591fa",
   "metadata": {},
   "source": [
    "# Другой подход к кластеризации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b705cb0",
   "metadata": {},
   "source": [
    "Пробуем новую идею, если не получается кластеризовать все обьекты, будем делать так: мы же уже знаем какие есть кластеры, просто раздадим метки по ключевым словам, олценим сколько осталось и проведем еще одну кластеризацию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7cfafca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target</th><th>user_id</th></tr><tr><td>i32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>1227381</td></tr><tr><td>1</td><td>647575</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌────────┬─────────┐\n",
       "│ target ┆ user_id │\n",
       "│ ---    ┆ ---     │\n",
       "│ i32    ┆ u32     │\n",
       "╞════════╪═════════╡\n",
       "│ 0      ┆ 1227381 │\n",
       "│ 1      ┆ 647575  │\n",
       "└────────┴─────────┘"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost\n",
    "import os\n",
    "from datetime import date, timedelta\n",
    "from itertools import combinations\n",
    "\n",
    "from local_utils import *\n",
    "import lightgbm as lgb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "test_start_date = date(2024, 8, 1)\n",
    "val_start_date = date(2024, 7, 1)\n",
    "val_end_date = date(2024, 7, 31)\n",
    "train_end_date = date(2024, 6, 30)\n",
    "data_path = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\AIM 2сем\\\\ML2\\\\hw2\"\n",
    "\n",
    "actions_history = pl.scan_parquet(os.path.join(data_path, 'actions_history/*.parquet')).collect()\n",
    "search_history = pl.scan_parquet(os.path.join(data_path, 'cluster_search/*.parquet')).collect()\n",
    "product_information = pl.read_csv(\n",
    "    os.path.join(data_path, 'cluster_product_information.csv'),\n",
    "    ignore_errors=True\n",
    ")\n",
    "\n",
    "val_target = (\n",
    "    actions_history\n",
    "    .filter(pl.col('timestamp').dt.date() >= val_start_date)\n",
    "    .filter(pl.col('timestamp').dt.date() <= val_end_date)\n",
    "    .select('user_id', (pl.col('action_type_id') == 3).alias('has_order'))\n",
    "    .group_by('user_id')\n",
    "    .agg(pl.max('has_order').cast(pl.Int32).alias('target'))\n",
    ")\n",
    "\n",
    "val_target.group_by('target').agg(pl.count('user_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5f61834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_aggs = {}\n",
    "actions_id_to_suf = {\n",
    "    1: \"click\",\n",
    "    2: \"favorite\", \n",
    "    3: \"order\",\n",
    "    5: \"to_cart\",\n",
    "}\n",
    "\n",
    "# Сначала соберем все агрегированные данные\n",
    "all_aggs = []\n",
    "numeric_features = []\n",
    "\n",
    "for id_, suf in actions_id_to_suf.items():\n",
    "    aggs = (\n",
    "        actions_history\n",
    "        .filter(pl.col('timestamp').dt.date() <= train_end_date)\n",
    "        .filter(pl.col('timestamp').dt.date() >= train_end_date - timedelta(days=30 * 4))\n",
    "        .filter(pl.col('action_type_id') == id_)\n",
    "        .join(\n",
    "            product_information.select('product_id', 'discount_price'),\n",
    "            on='product_id',\n",
    "        )\n",
    "        .group_by('user_id')\n",
    "        .agg(\n",
    "            pl.count('product_id').cast(pl.Int32).alias(f'num_products_{suf}'),\n",
    "            pl.sum('discount_price').cast(pl.Float32).alias(f'sum_discount_price_{suf}'),\n",
    "            pl.max('discount_price').cast(pl.Float32).alias(f'max_discount_price_{suf}'),\n",
    "            pl.max('timestamp').alias(f'last_{suf}_time'),\n",
    "            pl.min('timestamp').alias(f'first_{suf}_time'),\n",
    "        )\n",
    "        .with_columns([\n",
    "            (pl.lit(val_start_date) - pl.col(f'last_{suf}_time'))\n",
    "            .dt.total_days()\n",
    "            .cast(pl.Int32)\n",
    "            .alias(f'days_since_last_{suf}'),\n",
    "            \n",
    "            (pl.lit(val_start_date) - pl.col(f'first_{suf}_time'))\n",
    "            .dt.total_days()\n",
    "            .cast(pl.Int32)\n",
    "            .alias(f'days_since_first_{suf}'),\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    # Сохраняем имена числовых фичей для последующего создания полиномов\n",
    "    numeric_features.extend([\n",
    "        f'num_products_{suf}',\n",
    "        f'sum_discount_price_{suf}', \n",
    "        f'max_discount_price_{suf}',\n",
    "        f'days_since_last_{suf}',\n",
    "        f'days_since_first_{suf}',\n",
    "    ])\n",
    "    \n",
    "    actions_aggs[id_] = aggs\n",
    "    all_aggs.append(aggs)\n",
    "\n",
    "# Объединяем все агрегации по user_id с указанием суффиксов\n",
    "combined = all_aggs[0]\n",
    "for i, agg in enumerate(all_aggs[1:], 1):\n",
    "    combined = combined.join(\n",
    "        agg, \n",
    "        on='user_id', \n",
    "        how='left',\n",
    "        suffix=f\"_{i}\"  # Добавляем уникальный суффикс для каждого соединения\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "df901c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17072\\276488151.py:52: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  (pl.count() / (pl.max('timestamp') - pl.min('timestamp')).dt.total_days()).alias(f'{suf}_daily_rate'),\n"
     ]
    }
   ],
   "source": [
    "# search_aggs\n",
    "id_ = 4\n",
    "suf = 'search'\n",
    "\n",
    "# Сначала вычислим value_counts отдельно и развернем их в плоскую структуру\n",
    "cluster_counts = (\n",
    "    search_history\n",
    "    .filter(pl.col('action_type_id') == id_)\n",
    "    .filter(pl.col('timestamp').dt.date() <= train_end_date)\n",
    "    .filter(pl.col('timestamp').dt.date() >= train_end_date - timedelta(days=30 * 5))\n",
    "    .group_by('user_id')\n",
    "    .agg(\n",
    "        pl.col('cluster').value_counts().alias('cluster_counts')\n",
    "    )\n",
    "    .explode('cluster_counts')\n",
    "    .with_columns(\n",
    "        pl.col('cluster_counts').struct.field('cluster').alias('cluster_name'),\n",
    "        pl.col('cluster_counts').struct.field('count').alias('cluster_count')\n",
    "    )\n",
    "    .group_by('user_id')\n",
    "    .agg(\n",
    "        pl.col('cluster_name').sort_by('cluster_count', descending=True).head(3).alias('top3_clusters'),\n",
    "        pl.col('cluster_count').sort(descending=True).head(3).alias('top3_counts')\n",
    "    )\n",
    ")\n",
    "\n",
    "actions_aggs[id_] = (\n",
    "    search_history\n",
    "    .filter(pl.col('action_type_id') == id_)\n",
    "    .filter(pl.col('timestamp').dt.date() <= train_end_date)\n",
    "    .filter(pl.col('timestamp').dt.date() >= train_end_date - timedelta(days=30 * 5))\n",
    "    .group_by('user_id')\n",
    "    .agg(\n",
    "        # Общее количество поисков за 5 месяцев\n",
    "        pl.count('search_query').cast(pl.Int32).alias(f'num_{suf}'),\n",
    "        pl.col('search_query').n_unique().alias(f'unique_{suf}_queries'),\n",
    "        \n",
    "        # Количество поисков за последний месяц (30 дней)\n",
    "        pl.col('search_query')\n",
    "            .filter(pl.col('timestamp').dt.date() >= train_end_date - timedelta(days=30))\n",
    "            .count()\n",
    "            .cast(pl.Int32)\n",
    "            .alias(f'num_{suf}_last_month'),\n",
    "        \n",
    "        # Количество поисков за последнюю неделю (7 дней)\n",
    "        pl.col('search_query')\n",
    "            .filter(pl.col('timestamp').dt.date() >= train_end_date - timedelta(days=7))\n",
    "            .count()\n",
    "            .cast(pl.Int32)\n",
    "            .alias(f'num_{suf}_last_week'),\n",
    "\n",
    "        (pl.count() / (pl.max('timestamp') - pl.min('timestamp')).dt.total_days()).alias(f'{suf}_daily_rate'),\n",
    "\n",
    "        pl.col('cluster').n_unique().alias(f'num_{suf}_clusters'),\n",
    "        pl.col('cluster').mode().first().alias(f'main_{suf}_cluster'),\n",
    "        \n",
    "        # Динамика кластеров\n",
    "        pl.col('cluster')\n",
    "            .filter(pl.col('timestamp').dt.date() >= train_end_date - timedelta(days=30))\n",
    "            .mode().first()\n",
    "            .alias(f'recent_{suf}_cluster'),\n",
    "\n",
    "        (pl.col('cluster').value_counts().struct.field('count').max() / pl.col('cluster').count()).alias(f'{suf}_cluster_concentration'),\n",
    "        \n",
    "        # Энтропия кластеров (мера разнообразия)\n",
    "        (-(pl.col('cluster').value_counts().struct.field('count') / pl.col('cluster').count()).log()\n",
    "            * (pl.col('cluster').value_counts().struct.field('count') / pl.col('cluster').count())\n",
    "            .sum()).alias(f'{suf}_cluster_entropy'),\n",
    "        \n",
    "        # Переключения между кластерами\n",
    "        pl.col('cluster').diff().fill_null(0).abs().sum().alias(f'{suf}_cluster_switches'),\n",
    "        \n",
    "        # Стабильность кластеров (процент повторяющихся)\n",
    "        ((pl.col('cluster').count() - pl.col('cluster').n_unique()) / pl.col('cluster').count())\n",
    "            .alias(f'{suf}_cluster_stability'),\n",
    "        \n",
    "        # Время в основном кластере\n",
    "        (pl.col('timestamp')\n",
    "            .filter(pl.col('cluster') == pl.col('cluster').mode().first())\n",
    "            .count() / pl.col('timestamp').count())\n",
    "            .alias(f'main_{suf}_cluster_time_ratio'),\n",
    "\n",
    "        pl.col('timestamp').filter(pl.col('cluster').diff().fill_null(0) != 0)\n",
    "            .diff()\n",
    "            .dt.total_days()\n",
    "            .mean()\n",
    "            .alias(f'{suf}_mean_cluster_switch_days'),\n",
    "\n",
    "        pl.col('search_query').str.len_chars().mean().alias(f'{suf}_mean_query_len'),\n",
    "        \n",
    "        (pl.col('search_query').str.len_chars()\n",
    "            .filter(pl.col('cluster') == pl.col('cluster').mode().first()).mean() - \n",
    "            pl.col('search_query').str.len_chars()\n",
    "                .filter(pl.col('cluster') != pl.col('cluster').mode().first()).mean())\n",
    "                .alias(f'{suf}_main_cluster_query_len_diff'),\n",
    "\n",
    "        pl.max('timestamp').alias(f'last_{suf}_time'),\n",
    "        pl.min('timestamp').alias(f'first_{suf}_time'),\n",
    "    )\n",
    "    .join(cluster_counts, on='user_id', how='left')\n",
    "    .with_columns([\n",
    "        (pl.lit(val_start_date) - pl.col(f'last_{suf}_time'))\n",
    "            .dt.total_days()\n",
    "            .cast(pl.Int32)\n",
    "            .alias(f'days_since_last_{suf}'),\n",
    "\n",
    "        (pl.lit(val_start_date) - pl.col(f'first_{suf}_time'))\n",
    "            .dt.total_days()\n",
    "            .cast(pl.Int32)\n",
    "            .alias(f'days_since_first_{suf}'),\n",
    "    ])\n",
    "    .select(\n",
    "        'user_id',\n",
    "        f'num_{suf}',\n",
    "        f'unique_{suf}_queries',\n",
    "        f'num_{suf}_last_month',\n",
    "        f'num_{suf}_last_week',\n",
    "        f'{suf}_daily_rate',\n",
    "        f'num_{suf}_clusters',\n",
    "        f'main_{suf}_cluster',\n",
    "        pl.col('top3_clusters').alias(f'top3_{suf}_clusters'),\n",
    "        pl.col('top3_counts').alias(f'top3_{suf}_counts'),\n",
    "        f'recent_{suf}_cluster',\n",
    "        f'{suf}_cluster_concentration',\n",
    "        f'{suf}_cluster_entropy',\n",
    "        f'{suf}_cluster_switches',\n",
    "        f'{suf}_cluster_stability',\n",
    "        f'main_{suf}_cluster_time_ratio',\n",
    "        f'{suf}_mean_cluster_switch_days',\n",
    "        f'{suf}_mean_query_len',\n",
    "        f'{suf}_main_cluster_query_len_diff',\n",
    "        f'days_since_last_{suf}',\n",
    "        f'days_since_first_{suf}',\n",
    "        f'last_{suf}_time',\n",
    "        f'first_{suf}_time',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88399248",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_cluster_aggs = (\n",
    "    actions_history\n",
    "    .filter(pl.col('timestamp').dt.date() <= train_end_date)\n",
    "    .filter(pl.col('timestamp').dt.date() >= train_end_date - timedelta(days=30 * 5))\n",
    "    .join(\n",
    "        product_information.select('product_id', 'cluster'),\n",
    "        on='product_id'\n",
    "    )\n",
    "    .group_by('user_id')\n",
    "    .agg(\n",
    "        # Общие агрегаты по кластерам продуктов\n",
    "        pl.col('cluster').n_unique().alias('num_product_clusters'),\n",
    "        pl.col('cluster').mode().first().alias('main_product_cluster'),\n",
    "        \n",
    "        # Аналогичные агрегаты как для search\n",
    "        (pl.col('cluster').value_counts().struct.field('count').max() / pl.col('cluster').count()).alias('product_cluster_concentration'),\n",
    "        \n",
    "        # Энтропия кластеров продуктов\n",
    "        (-(pl.col('cluster').value_counts().struct.field('count') / pl.col('cluster').count()).log()\n",
    "            * (pl.col('cluster').value_counts().struct.field('count') / pl.col('cluster').count())\n",
    "            .sum()).alias('product_cluster_entropy'),\n",
    "        \n",
    "        # Стабильность кластеров продуктов\n",
    "        ((pl.col('cluster').count() - pl.col('cluster').n_unique()) / pl.col('cluster').count())\n",
    "            .alias('product_cluster_stability'),\n",
    "        \n",
    "        # Время в основном кластере продуктов\n",
    "        (pl.col('timestamp')\n",
    "            .filter(pl.col('cluster') == pl.col('cluster').mode().first())\n",
    "            .count() / pl.col('timestamp').count()\n",
    "        ).alias('main_product_cluster_time_ratio'),\n",
    "            \n",
    "        # Top 3 кластеров продуктов\n",
    "        pl.col('cluster').value_counts().struct.field('cluster').alias('top_product_clusters'),\n",
    "        pl.col('cluster').value_counts().struct.field('count').alias('top_product_counts')\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col('top_product_clusters').list.head(3).alias('top3_product_clusters'),\n",
    "        pl.col('top_product_counts').list.head(3).alias('top3_product_counts')\n",
    "    )\n",
    "    .drop(['top_product_clusters', 'top_product_counts'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "582ce0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17072\\1964511306.py:14: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias('total_actions_30d'),\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17072\\1964511306.py:31: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  (pl.col('cluster').value_counts().struct.field('count').max() / pl.count()).alias('main_cluster_ratio_30d')\n"
     ]
    }
   ],
   "source": [
    "train_last_month_features = (\n",
    "    actions_history\n",
    "    .filter(\n",
    "        (pl.col('timestamp').dt.date() < val_start_date) &  # до валидации\n",
    "        (pl.col('timestamp').dt.date() >= val_start_date - timedelta(days=30))  # последние 30 дней\n",
    "    )\n",
    "    .join(\n",
    "        product_information.select('product_id', 'discount_price', 'cluster'),\n",
    "        on='product_id'\n",
    "    )\n",
    "    .group_by('user_id')\n",
    "    .agg(\n",
    "        # Общая активность\n",
    "        pl.count().alias('total_actions_30d'),\n",
    "        \n",
    "        # Разбивка по типам действий\n",
    "        (pl.col('action_type_id') == 1).sum().alias('clicks_30d'),\n",
    "        (pl.col('action_type_id') == 2).sum().alias('favorites_30d'),\n",
    "        (pl.col('action_type_id') == 5).sum().alias('cart_adds_30d'),\n",
    "        \n",
    "        # Финансовые метрики\n",
    "        pl.sum('discount_price').alias('total_spent_30d'),\n",
    "        pl.mean('discount_price').alias('avg_price_30d'),\n",
    "        \n",
    "        # Временные характеристики (исправлено!)\n",
    "        (val_start_date - pl.col('timestamp').max().dt.date()).dt.total_days().alias('days_since_last_action'),\n",
    "        (pl.col('timestamp').max() - pl.col('timestamp').min()).dt.total_days().alias('active_days_30d'),\n",
    "        \n",
    "        # Метрики кластеров\n",
    "        pl.col('cluster').n_unique().alias('unique_clusters_30d'),\n",
    "        (pl.col('cluster').value_counts().struct.field('count').max() / pl.count()).alias('main_cluster_ratio_30d')\n",
    "    )\n",
    "    .with_columns(\n",
    "        # Производные признаки\n",
    "        (pl.col('total_actions_30d') / pl.col('active_days_30d')).alias('daily_actions_rate_30d'),\n",
    "        (pl.col('cart_adds_30d') / pl.col('total_actions_30d')).alias('cart_add_ratio_30d'),\n",
    "        (pl.col('favorites_30d') / pl.col('total_actions_30d')).alias('favorite_ratio_30d')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c6a83618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = val_target\n",
    "for _, actions_aggs_df in actions_aggs.items():\n",
    "    df_main = (\n",
    "        df_main\n",
    "        .join(actions_aggs_df, on='user_id', how='left')\n",
    "    )\n",
    "\n",
    "df_main = df_main.join(product_cluster_aggs, on='user_id', how='left')\n",
    "df_main = df_main.join(train_last_month_features, on='user_id', how='left')\n",
    "    \n",
    "df_pd = df_main.to_pandas()\n",
    "\n",
    "columns_to_log = ['max_discount_price_click', 'num_products_favorite', 'sum_discount_price_favorite', 'max_discount_price_favorite',  'num_products_order', 'sum_discount_price_order', 'sum_discount_price_order',  'num_products_to_cart', 'max_discount_price_to_cart', 'num_search', 'unique_search_queries', 'num_search_last_month', 'num_search_last_week', 'search_daily_rate', 'search_cluster_switches', 'search_mean_query_len', 'search_main_cluster_query_len_diff']\n",
    "\n",
    "df_pd = apply_log_transform(df_pd, columns_to_log, drop_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3937b516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65b6266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4bde7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "00f46198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nans filled\n"
     ]
    }
   ],
   "source": [
    "from local_utils import *\n",
    "\n",
    "pca_cols = list(set(df_pd.columns) - {'user_id', 'target', 'last_click_time', 'first_click_time', 'last_favorite_time', 'first_favorite_time', \n",
    "                                'last_order_time', 'first_order_time', 'last_to_cart_time', 'first_to_cart_time', 'last_search_time', 'first_search_time',\n",
    "                                'top3_search_clusters', 'top3_search_counts', 'search_cluster_entropy', 'top3_product_counts', 'product_cluster_entropy', 'top3_product_clusters'})\n",
    "df_pd = add_pca_columns(df_pd,  pca_cols,  n_components = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b9a90335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nans filled\n",
      "Data scaled\n",
      "Using CPU\n",
      "FAISS index built\n",
      "KNN search done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:118: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:152: RuntimeWarning: overflow encountered in reduce\n",
      "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN features created\n"
     ]
    }
   ],
   "source": [
    "knn_cols = ['days_since_first_order', 'days_since_last_order', 'sum_discount_price_to_cart', 'num_products_click', 'main_search_cluster', 'search_cluster_stability', 'product_cluster_stability']\n",
    "\n",
    "df_pd = add_knn_features_faiss(df_pd, knn_cols, n_neighbors=5, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89385d9",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcbca9c",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f200c7f5",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d00f3687",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = df_pd[df_pd['user_id'] != 2346229]\n",
    "\n",
    "cols = list(set(df_pd.columns) - {'user_id', 'target', 'last_click_time', 'first_click_time', 'last_favorite_time', 'first_favorite_time', \n",
    "                                'last_order_time', 'first_order_time', 'last_to_cart_time', 'first_to_cart_time', 'last_search_time', 'first_search_time',\n",
    "                                'top3_search_clusters', 'top3_search_counts', 'search_cluster_entropy', 'top3_product_counts', 'product_cluster_entropy', 'top3_product_clusters'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fd4cee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'learning_rate': 0.01,\n",
    "    'depth': 10,  # Аналог max_depth в LGBM\n",
    "    'iterations': 900,\n",
    "    'early_stopping_rounds': 60,\n",
    "    'verbose': 1,\n",
    "    'random_seed': 42,\n",
    "    'thread_count': -1,  # Использовать все ядра\n",
    "    'grow_policy': 'Lossguide', # Более быстрый режим роста\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "361fa9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.01,    # Можно уменьшить до 0.005 для большей точности\n",
    "    \n",
    "    'max_depth': 120,\n",
    "    'num_leaves': 75,\n",
    "    'min_data_in_leaf': 30,\n",
    "    \n",
    "    # Настройки обучения\n",
    "    'num_iterations': 900,    # Можно увеличить при ранней остановке\n",
    "    'early_stopping_rounds': 60,\n",
    "    'seed': 42,               # Для воспроизводимости\n",
    "    \n",
    "    # Дополнительно\n",
    "    'verbose': 1,\n",
    "    'importance_type': 'split',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65daf8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f1241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bda34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d1e249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e4232f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3e5a2dc",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070d59b",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c184c11",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b9ad191a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17072\\2116881979.py:59: DeprecationWarning: Use of `how='outer'` should be replaced with `how='full'`.\n",
      "  combined_val = combined_val.join(\n"
     ]
    }
   ],
   "source": [
    "actions_aggs = {}\n",
    "actions_id_to_suf = {\n",
    "    1: \"click\",\n",
    "    2: \"favorite\", \n",
    "    3: \"order\",\n",
    "    5: \"to_cart\",\n",
    "}\n",
    "\n",
    "# Сначала соберем все агрегированные данные\n",
    "all_aggs = []\n",
    "numeric_features = []\n",
    "\n",
    "for id_, suf in actions_id_to_suf.items():\n",
    "    aggs = (\n",
    "        actions_history\n",
    "        .filter(pl.col('timestamp').dt.date() <= val_end_date)\n",
    "        .filter(pl.col('timestamp').dt.date() >= val_end_date - timedelta(days=30 * 5))\n",
    "        .filter(pl.col('action_type_id') == id_)\n",
    "        .join(\n",
    "            product_information.select('product_id', 'discount_price'),\n",
    "            on='product_id',\n",
    "        )\n",
    "        .group_by('user_id')\n",
    "        .agg(\n",
    "            pl.count('product_id').cast(pl.Int32).alias(f'num_products_{suf}'),\n",
    "            pl.sum('discount_price').cast(pl.Float32).alias(f'sum_discount_price_{suf}'),\n",
    "            pl.max('discount_price').cast(pl.Float32).alias(f'max_discount_price_{suf}'),\n",
    "            pl.max('timestamp').alias(f'last_{suf}_time'),\n",
    "            pl.min('timestamp').alias(f'first_{suf}_time'),\n",
    "        )\n",
    "        .with_columns([\n",
    "            (pl.lit(test_start_date) - pl.col(f'last_{suf}_time'))\n",
    "            .dt.total_days()\n",
    "            .cast(pl.Int32)\n",
    "            .alias(f'days_since_last_{suf}'),\n",
    "            \n",
    "            (pl.lit(test_start_date) - pl.col(f'first_{suf}_time'))\n",
    "            .dt.total_days()\n",
    "            .cast(pl.Int32)\n",
    "            .alias(f'days_since_first_{suf}'),\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    # Сохраняем имена числовых фичей для создания полиномов\n",
    "    numeric_features.extend([\n",
    "        f'num_products_{suf}',\n",
    "        f'sum_discount_price_{suf}', \n",
    "        f'max_discount_price_{suf}',\n",
    "        f'days_since_last_{suf}',\n",
    "        f'days_since_first_{suf}',\n",
    "    ])\n",
    "    \n",
    "    actions_aggs[id_] = aggs\n",
    "    all_aggs.append(aggs)\n",
    "\n",
    "# Объединяем все агрегации по user_id с суффиксами\n",
    "combined_val = all_aggs[0]\n",
    "for i, agg in enumerate(all_aggs[1:], 1):\n",
    "    combined_val = combined_val.join(\n",
    "        agg, \n",
    "        on='user_id', \n",
    "        how='outer',\n",
    "        suffix=f\"_{i}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "81add27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17072\\555555092.py:51: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  (pl.count() / (pl.max('timestamp') - pl.min('timestamp')).dt.total_days()).alias(f'{suf}_daily_rate'),\n"
     ]
    }
   ],
   "source": [
    "id_ = 4\n",
    "suf = 'search'\n",
    "\n",
    "# Вычисляем top3 кластеров для валидации (аналогично трейну)\n",
    "val_cluster_counts = (\n",
    "    search_history\n",
    "    .filter(pl.col('action_type_id') == id_)\n",
    "    .filter(pl.col('timestamp').dt.date() <= val_end_date)\n",
    "    .filter(pl.col('timestamp').dt.date() >= val_end_date - timedelta(days=30 * 5))\n",
    "    .group_by('user_id')\n",
    "    .agg(\n",
    "        pl.col('cluster').value_counts().alias('cluster_counts')\n",
    "    )\n",
    "    .explode('cluster_counts')\n",
    "    .with_columns(\n",
    "        pl.col('cluster_counts').struct.field('cluster').alias('cluster_name'),\n",
    "        pl.col('cluster_counts').struct.field('count').alias('cluster_count')\n",
    "    )\n",
    "    .group_by('user_id')\n",
    "    .agg(\n",
    "        pl.col('cluster_name').sort_by('cluster_count', descending=True).head(3).alias('top3_clusters'),\n",
    "        pl.col('cluster_count').sort(descending=True).head(3).alias('top3_counts')\n",
    "    )\n",
    ")\n",
    "\n",
    "actions_aggs[id_] = (\n",
    "    search_history\n",
    "    .filter(pl.col('action_type_id') == id_)\n",
    "    .filter(pl.col('timestamp').dt.date() <= val_end_date)\n",
    "    .filter(pl.col('timestamp').dt.date() >= val_end_date - timedelta(days=30 * 5))\n",
    "    .group_by('user_id')\n",
    "    .agg(\n",
    "        # Общее количество поисков за 5 месяцев\n",
    "        pl.count('search_query').cast(pl.Int32).alias(f'num_{suf}'),\n",
    "        pl.col('search_query').n_unique().alias(f'unique_{suf}_queries'),\n",
    "        \n",
    "        # Количество поисков за последний месяц (30 дней)\n",
    "        pl.col('search_query')\n",
    "            .filter(pl.col('timestamp').dt.date() >= val_end_date - timedelta(days=30))\n",
    "            .count()\n",
    "            .cast(pl.Int32)\n",
    "            .alias(f'num_{suf}_last_month'),\n",
    "        \n",
    "        # Количество поисков за последнюю неделю (7 дней)\n",
    "        pl.col('search_query')\n",
    "            .filter(pl.col('timestamp').dt.date() >= val_end_date - timedelta(days=7))\n",
    "            .count()\n",
    "            .cast(pl.Int32)\n",
    "            .alias(f'num_{suf}_last_week'),\n",
    "\n",
    "        (pl.count() / (pl.max('timestamp') - pl.min('timestamp')).dt.total_days()).alias(f'{suf}_daily_rate'),\n",
    "\n",
    "        pl.col('cluster').n_unique().alias(f'num_{suf}_clusters'),\n",
    "        pl.col('cluster').mode().first().alias(f'main_{suf}_cluster'),\n",
    "        \n",
    "        # Динамика кластеров\n",
    "        pl.col('cluster')\n",
    "            .filter(pl.col('timestamp').dt.date() >= val_end_date - timedelta(days=30))\n",
    "            .mode().first()\n",
    "            .alias(f'recent_{suf}_cluster'),\n",
    "\n",
    "        (pl.col('cluster').value_counts().struct.field('count').max() / pl.col('cluster').count()).alias(f'{suf}_cluster_concentration'),\n",
    "        \n",
    "        # Энтропия кластеров\n",
    "        (-(pl.col('cluster').value_counts().struct.field('count') / pl.col('cluster').count()).log()\n",
    "            * (pl.col('cluster').value_counts().struct.field('count') / pl.col('cluster').count())\n",
    "            .sum()).alias(f'{suf}_cluster_entropy'),\n",
    "        \n",
    "        # Переключения между кластерами\n",
    "        pl.col('cluster').diff().fill_null(0).abs().sum().alias(f'{suf}_cluster_switches'),\n",
    "        \n",
    "        # Стабильность кластеров\n",
    "        ((pl.col('cluster').count() - pl.col('cluster').n_unique()) / pl.col('cluster').count())\n",
    "            .alias(f'{suf}_cluster_stability'),\n",
    "        \n",
    "        # Время в основном кластере\n",
    "        (pl.col('timestamp')\n",
    "            .filter(pl.col('cluster') == pl.col('cluster').mode().first())\n",
    "            .count() / pl.col('timestamp').count())\n",
    "            .alias(f'main_{suf}_cluster_time_ratio'),\n",
    "\n",
    "        pl.col('timestamp').filter(pl.col('cluster').diff().fill_null(0) != 0)\n",
    "            .diff()\n",
    "            .dt.total_days()\n",
    "            .mean()\n",
    "            .alias(f'{suf}_mean_cluster_switch_days'),\n",
    "\n",
    "        pl.col('search_query').str.len_chars().mean().alias(f'{suf}_mean_query_len'),\n",
    "        \n",
    "        (pl.col('search_query').str.len_chars()\n",
    "            .filter(pl.col('cluster') == pl.col('cluster').mode().first()).mean() - \n",
    "            pl.col('search_query').str.len_chars()\n",
    "                .filter(pl.col('cluster') != pl.col('cluster').mode().first()).mean())\n",
    "                .alias(f'{suf}_main_cluster_query_len_diff'),\n",
    "\n",
    "        pl.max('timestamp').alias(f'last_{suf}_time'),\n",
    "        pl.min('timestamp').alias(f'first_{suf}_time'),\n",
    "    )\n",
    "    .join(val_cluster_counts, on='user_id', how='left')\n",
    "    .with_columns([\n",
    "        (pl.lit(test_start_date) - pl.col(f'last_{suf}_time'))\n",
    "            .dt.total_days()\n",
    "            .cast(pl.Int32)\n",
    "            .alias(f'days_since_last_{suf}'),\n",
    "\n",
    "        (pl.lit(test_start_date) - pl.col(f'first_{suf}_time'))\n",
    "            .dt.total_days()\n",
    "            .cast(pl.Int32)\n",
    "            .alias(f'days_since_first_{suf}'),\n",
    "    ])\n",
    "    .select(\n",
    "        'user_id',\n",
    "        f'num_{suf}',\n",
    "        f'unique_{suf}_queries',\n",
    "        f'num_{suf}_last_month',\n",
    "        f'num_{suf}_last_week',\n",
    "        f'{suf}_daily_rate',\n",
    "        f'num_{suf}_clusters',\n",
    "        f'main_{suf}_cluster',\n",
    "        pl.col('top3_clusters').alias(f'top3_{suf}_clusters'),\n",
    "        pl.col('top3_counts').alias(f'top3_{suf}_counts'),\n",
    "        f'recent_{suf}_cluster',\n",
    "        f'{suf}_cluster_concentration',\n",
    "        f'{suf}_cluster_entropy',\n",
    "        f'{suf}_cluster_switches',\n",
    "        f'{suf}_cluster_stability',\n",
    "        f'main_{suf}_cluster_time_ratio',\n",
    "        f'{suf}_mean_cluster_switch_days',\n",
    "        f'{suf}_mean_query_len',\n",
    "        f'{suf}_main_cluster_query_len_diff',\n",
    "        f'days_since_last_{suf}',\n",
    "        f'days_since_first_{suf}',\n",
    "        f'last_{suf}_time',\n",
    "        f'first_{suf}_time',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a829d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_product_cluster_aggs = (\n",
    "    actions_history\n",
    "    .filter(pl.col('timestamp').dt.date() <= val_end_date)\n",
    "    .filter(pl.col('timestamp').dt.date() >= val_end_date - timedelta(days=30 * 5))\n",
    "    .join(\n",
    "        product_information.select('product_id', 'cluster'),\n",
    "        on='product_id'\n",
    "    )\n",
    "    .group_by('user_id')\n",
    "    .agg(\n",
    "        # Общие агрегаты по кластерам продуктов\n",
    "        pl.col('cluster').n_unique().alias('num_product_clusters'),\n",
    "        pl.col('cluster').mode().first().alias('main_product_cluster'),\n",
    "        \n",
    "        # Аналогичные агрегаты как для search\n",
    "        (pl.col('cluster').value_counts().struct.field('count').max() / pl.col('cluster').count()).alias('product_cluster_concentration'),\n",
    "        \n",
    "        # Энтропия кластеров продуктов\n",
    "        (-(pl.col('cluster').value_counts().struct.field('count') / pl.col('cluster').count()).log()\n",
    "            * (pl.col('cluster').value_counts().struct.field('count') / pl.col('cluster').count())\n",
    "            .sum()).alias('product_cluster_entropy'),\n",
    "        \n",
    "        # Стабильность кластеров продуктов\n",
    "        ((pl.col('cluster').count() - pl.col('cluster').n_unique()) / pl.col('cluster').count())\n",
    "            .alias('product_cluster_stability'),\n",
    "        \n",
    "        # Время в основном кластере продуктов\n",
    "        (pl.col('timestamp')\n",
    "            .filter(pl.col('cluster') == pl.col('cluster').mode().first())\n",
    "            .count() / pl.col('timestamp').count()\n",
    "        ).alias('main_product_cluster_time_ratio'),\n",
    "            \n",
    "        # Top 3 кластеров продуктов\n",
    "        pl.col('cluster').value_counts().struct.field('cluster').alias('top_product_clusters'),\n",
    "        pl.col('cluster').value_counts().struct.field('count').alias('top_product_counts')\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col('top_product_clusters').list.head(3).alias('top3_product_clusters'),\n",
    "        pl.col('top_product_counts').list.head(3).alias('top3_product_counts')\n",
    "    )\n",
    "    .drop(['top_product_clusters', 'top_product_counts'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9872e1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17072\\4126633476.py:14: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias('total_actions_30d'),\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17072\\4126633476.py:26: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  (pl.col('cluster').value_counts().struct.field('count').max() / pl.count()).alias('main_cluster_ratio_30d')\n"
     ]
    }
   ],
   "source": [
    "test_last_month_features = (\n",
    "    actions_history\n",
    "    .filter(\n",
    "        (pl.col('timestamp').dt.date() < test_start_date) &  # до теста\n",
    "        (pl.col('timestamp').dt.date() >= test_start_date - timedelta(days=30))  # последние 30 дней\n",
    "    )\n",
    "    .join(\n",
    "        product_information.select('product_id', 'discount_price', 'cluster'),\n",
    "        on='product_id'\n",
    "    )\n",
    "    .group_by('user_id')\n",
    "    .agg(\n",
    "        # Те же метрики, что и для трейна\n",
    "        pl.count().alias('total_actions_30d'),\n",
    "        (pl.col('action_type_id') == 1).sum().alias('clicks_30d'),\n",
    "        (pl.col('action_type_id') == 2).sum().alias('favorites_30d'),\n",
    "        (pl.col('action_type_id') == 5).sum().alias('cart_adds_30d'),\n",
    "        \n",
    "        pl.sum('discount_price').alias('total_spent_30d'),\n",
    "        pl.mean('discount_price').alias('avg_price_30d'),\n",
    "        \n",
    "        (test_start_date - pl.col('timestamp').max().dt.date()).dt.total_days().alias('days_since_last_action'),\n",
    "        (pl.col('timestamp').max() - pl.col('timestamp').min()).dt.total_days().alias('active_days_30d'),\n",
    "        \n",
    "        pl.col('cluster').n_unique().alias('unique_clusters_30d'),\n",
    "        (pl.col('cluster').value_counts().struct.field('count').max() / pl.count()).alias('main_cluster_ratio_30d')\n",
    "    )\n",
    "    .with_columns(\n",
    "        (pl.col('total_actions_30d') / pl.col('active_days_30d')).alias('daily_actions_rate_30d'),\n",
    "        (pl.col('cart_adds_30d') / pl.col('total_actions_30d')).alias('cart_add_ratio_30d'),\n",
    "        (pl.col('favorites_30d') / pl.col('total_actions_30d')).alias('favorite_ratio_30d')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "67c2ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_utils import *\n",
    "\n",
    "test_df_main = test_users_submission\n",
    "for _, actions_aggs_df in actions_aggs.items():\n",
    "    test_df_main = (\n",
    "        test_df_main\n",
    "        .join(actions_aggs_df, on='user_id', how='left')\n",
    "    )\n",
    "test_df_main = test_df_main.join(val_product_cluster_aggs, on='user_id', how='left')\n",
    "test_df_main = test_df_main.join(test_last_month_features, on='user_id', how='left')\n",
    "\n",
    "test_df_pd = test_df_main.to_pandas()\n",
    "\n",
    "test_df_pd = apply_log_transform(test_df_pd, columns_to_log, drop_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "89010e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nans filled\n"
     ]
    }
   ],
   "source": [
    "test_df_pd = add_pca_columns(test_df_pd,  pca_cols,  n_components = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "95d7ef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nans filled\n",
      "Data scaled\n",
      "Using CPU\n",
      "FAISS index built\n",
      "KNN search done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:118: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:152: RuntimeWarning: overflow encountered in reduce\n",
      "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN features created\n"
     ]
    }
   ],
   "source": [
    "test_df_pd = add_knn_features_faiss(test_df_pd, knn_cols, n_neighbors=5, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1535c2e6",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7ecc2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "def bagging_predict(model_fn, X, n_estimators=10, sample_size=0.8, random_state=42):\n",
    "    \"\"\"\n",
    "    Функция для выполнения бэггинга\n",
    "    :param model_fn: Функция, которая создает и обучает модель (должна возвращать обученную модель)\n",
    "    :param X: Данные для обучения\n",
    "    :param n_estimators: Количество моделей в ансамбле\n",
    "    :param sample_size: Размер подвыборки (от 0 до 1)\n",
    "    :param random_state: Random seed для воспроизводимости\n",
    "    :return: Средние предсказания всех моделей\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    predictions = []\n",
    "    \n",
    "    n_samples = int(len(X) * sample_size)\n",
    "    \n",
    "    for i in range(n_estimators):\n",
    "        # Создаем бутстрап выборку\n",
    "        X_sample = resample(X, n_samples=n_samples, random_state=random_state+i)\n",
    "        \n",
    "        # Обучаем модель на подвыборке\n",
    "        model = model_fn(X_sample)\n",
    "        \n",
    "        # Делаем предсказание на всех данных\n",
    "        pred = model.predict_proba(test_df_pd[cols])[:, 1]\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Возвращаем среднее предсказание\n",
    "    return np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2fcb7027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7451761\tbest: 0.7451761 (0)\ttotal: 505ms\tremaining: 7m 33s\n",
      "100:\ttest: 0.7517976\tbest: 0.7517976 (100)\ttotal: 51s\tremaining: 6m 43s\n",
      "200:\ttest: 0.7568969\tbest: 0.7568969 (200)\ttotal: 1m 42s\tremaining: 5m 57s\n",
      "300:\ttest: 0.7584540\tbest: 0.7584540 (300)\ttotal: 2m 39s\tremaining: 5m 17s\n",
      "400:\ttest: 0.7591171\tbest: 0.7591171 (400)\ttotal: 3m 39s\tremaining: 4m 33s\n",
      "500:\ttest: 0.7598047\tbest: 0.7598047 (500)\ttotal: 4m 48s\tremaining: 3m 50s\n",
      "600:\ttest: 0.7599711\tbest: 0.7599942 (568)\ttotal: 6m 6s\tremaining: 3m 2s\n",
      "700:\ttest: 0.7602293\tbest: 0.7602293 (700)\ttotal: 7m 23s\tremaining: 2m 6s\n",
      "800:\ttest: 0.7603801\tbest: 0.7604099 (786)\ttotal: 8m 43s\tremaining: 1m 4s\n",
      "899:\ttest: 0.7604749\tbest: 0.7605193 (893)\ttotal: 10m 2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7605192982\n",
      "bestIteration = 893\n",
      "\n",
      "Shrink model to first 894 iterations.\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] early_stopping_round is set=60, early_stopping_rounds=60 will be ignored. Current value: early_stopping_round=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Number of positive: 698755, number of negative: 1326286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 24789\n",
      "[LightGBM] [Info] Number of data points in the train set: 2025041, number of used features: 124\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] early_stopping_round is set=60, early_stopping_rounds=60 will be ignored. Current value: early_stopping_round=60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345057 -> initscore=-0.640838\n",
      "[LightGBM] [Info] Start training from score -0.640838\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "Early stopping, best iteration is:\n",
      "[442]\tvalid_0's auc: 0.760951\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n"
     ]
    }
   ],
   "source": [
    "# Функция для создания CatBoost модели\n",
    "def create_catboost_model(X_sample):\n",
    "    tr, val = get_split(X_sample, val_size=0.25, random_state=42)\n",
    "    model = train_catboost_model(tr, val, cols, 'target', params=params, shadow_features=False, sklearn_style=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Функция для создания LGBM модели\n",
    "def create_lgb_model(X_sample):\n",
    "    tr, val = get_split(X_sample, val_size=0.25, random_state=41)\n",
    "    model = train_model(tr, val, cols, 'target', params=lgb_params, shadow_features=False, sklearn_style=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Количество моделей в бэггинге\n",
    "N_ESTIMATORS = 10\n",
    "\n",
    "# Получаем предсказания с бэггингом\n",
    "test_df_pd['catboost_predict'] = bagging_predict(create_catboost_model, df_pd, n_estimators=1)\n",
    "test_df_pd['lgb_predict'] = bagging_predict(create_lgb_model, df_pd, n_estimators=1)\n",
    "\n",
    "# Усредняем предсказания\n",
    "test_df_pd['predict'] = test_df_pd[['catboost_predict', 'lgb_predict']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "39d3ba74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>num_products_click</th>\n",
       "      <th>sum_discount_price_click</th>\n",
       "      <th>last_click_time</th>\n",
       "      <th>first_click_time</th>\n",
       "      <th>days_since_last_click</th>\n",
       "      <th>days_since_first_click</th>\n",
       "      <th>last_favorite_time</th>\n",
       "      <th>first_favorite_time</th>\n",
       "      <th>days_since_last_favorite</th>\n",
       "      <th>...</th>\n",
       "      <th>knn_product_cluster_stability_max</th>\n",
       "      <th>knn_product_cluster_stability_min</th>\n",
       "      <th>knn_product_cluster_stability_std</th>\n",
       "      <th>knn_product_cluster_stability_median</th>\n",
       "      <th>knn_product_cluster_stability_sum</th>\n",
       "      <th>knn_product_cluster_stability_range</th>\n",
       "      <th>knn_product_cluster_stability_weighted_mean</th>\n",
       "      <th>catboost_predict</th>\n",
       "      <th>lgb_predict</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1342</td>\n",
       "      <td>-0.008982</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>2024-04-21 15:03:11</td>\n",
       "      <td>2024-04-21 15:03:11</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2024-04-21 15:06:25</td>\n",
       "      <td>2024-04-21 15:06:25</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-8.051726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.186936</td>\n",
       "      <td>0.177770</td>\n",
       "      <td>0.182353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9852</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>14359.0</td>\n",
       "      <td>2024-07-11 06:51:15</td>\n",
       "      <td>2024-03-03 10:24:47</td>\n",
       "      <td>20.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-8.051726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.770885</td>\n",
       "      <td>0.812942</td>\n",
       "      <td>0.791914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10206</td>\n",
       "      <td>-0.009361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-8.051726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.224634</td>\n",
       "      <td>0.213430</td>\n",
       "      <td>0.219032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11317</td>\n",
       "      <td>-0.009361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-8.051726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.234096</td>\n",
       "      <td>0.222648</td>\n",
       "      <td>0.228372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13289</td>\n",
       "      <td>-0.009361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-8.051726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.579569</td>\n",
       "      <td>0.615995</td>\n",
       "      <td>0.597782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068419</th>\n",
       "      <td>11157283</td>\n",
       "      <td>-0.009361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-8.051726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.199867</td>\n",
       "      <td>0.213342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068420</th>\n",
       "      <td>11160395</td>\n",
       "      <td>-0.009361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-16 18:42:57</td>\n",
       "      <td>2024-04-16 18:42:57</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-8.051726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.181089</td>\n",
       "      <td>0.152042</td>\n",
       "      <td>0.166566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068421</th>\n",
       "      <td>11165052</td>\n",
       "      <td>-0.005949</td>\n",
       "      <td>2515.0</td>\n",
       "      <td>2024-07-25 22:37:15</td>\n",
       "      <td>2024-04-04 01:23:31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374736</td>\n",
       "      <td>0.303841</td>\n",
       "      <td>0.026850</td>\n",
       "      <td>0.336562</td>\n",
       "      <td>1.726437</td>\n",
       "      <td>0.070896</td>\n",
       "      <td>0.336573</td>\n",
       "      <td>0.585023</td>\n",
       "      <td>0.545881</td>\n",
       "      <td>0.565452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068422</th>\n",
       "      <td>11168218</td>\n",
       "      <td>-0.007844</td>\n",
       "      <td>870.0</td>\n",
       "      <td>2024-06-27 18:48:23</td>\n",
       "      <td>2024-04-04 06:00:33</td>\n",
       "      <td>34.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.043623</td>\n",
       "      <td>0.825891</td>\n",
       "      <td>0.070319</td>\n",
       "      <td>0.920634</td>\n",
       "      <td>4.667326</td>\n",
       "      <td>0.217731</td>\n",
       "      <td>0.920638</td>\n",
       "      <td>0.577050</td>\n",
       "      <td>0.574712</td>\n",
       "      <td>0.575881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068423</th>\n",
       "      <td>11172313</td>\n",
       "      <td>-0.008982</td>\n",
       "      <td>449.0</td>\n",
       "      <td>2024-06-23 16:34:33</td>\n",
       "      <td>2024-06-23 16:34:33</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>-8.051726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.610345</td>\n",
       "      <td>0.523044</td>\n",
       "      <td>0.527067</td>\n",
       "      <td>0.525056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2068424 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  num_products_click  sum_discount_price_click  \\\n",
       "0            1342           -0.008982                    1213.0   \n",
       "1            9852            0.004668                   14359.0   \n",
       "2           10206           -0.009361                       NaN   \n",
       "3           11317           -0.009361                       NaN   \n",
       "4           13289           -0.009361                       NaN   \n",
       "...           ...                 ...                       ...   \n",
       "2068419  11157283           -0.009361                       NaN   \n",
       "2068420  11160395           -0.009361                       NaN   \n",
       "2068421  11165052           -0.005949                    2515.0   \n",
       "2068422  11168218           -0.007844                     870.0   \n",
       "2068423  11172313           -0.008982                     449.0   \n",
       "\n",
       "            last_click_time    first_click_time  days_since_last_click  \\\n",
       "0       2024-04-21 15:03:11 2024-04-21 15:03:11                  101.0   \n",
       "1       2024-07-11 06:51:15 2024-03-03 10:24:47                   20.0   \n",
       "2                       NaT                 NaT                    NaN   \n",
       "3                       NaT                 NaT                    NaN   \n",
       "4                       NaT                 NaT                    NaN   \n",
       "...                     ...                 ...                    ...   \n",
       "2068419                 NaT                 NaT                    NaN   \n",
       "2068420                 NaT                 NaT                    NaN   \n",
       "2068421 2024-07-25 22:37:15 2024-04-04 01:23:31                    6.0   \n",
       "2068422 2024-06-27 18:48:23 2024-04-04 06:00:33                   34.0   \n",
       "2068423 2024-06-23 16:34:33 2024-06-23 16:34:33                   38.0   \n",
       "\n",
       "         days_since_first_click  last_favorite_time first_favorite_time  \\\n",
       "0                         101.0 2024-04-21 15:06:25 2024-04-21 15:06:25   \n",
       "1                         150.0                 NaT                 NaT   \n",
       "2                           NaN                 NaT                 NaT   \n",
       "3                           NaN                 NaT                 NaT   \n",
       "4                           NaN                 NaT                 NaT   \n",
       "...                         ...                 ...                 ...   \n",
       "2068419                     NaN                 NaT                 NaT   \n",
       "2068420                     NaN 2024-04-16 18:42:57 2024-04-16 18:42:57   \n",
       "2068421                   118.0                 NaT                 NaT   \n",
       "2068422                   118.0                 NaT                 NaT   \n",
       "2068423                    38.0                 NaT                 NaT   \n",
       "\n",
       "         days_since_last_favorite  ...  knn_product_cluster_stability_max  \\\n",
       "0                           101.0  ...                          -1.610345   \n",
       "1                             NaN  ...                          -1.610345   \n",
       "2                             NaN  ...                          -1.610345   \n",
       "3                             NaN  ...                          -1.610345   \n",
       "4                             NaN  ...                          -1.610345   \n",
       "...                           ...  ...                                ...   \n",
       "2068419                       NaN  ...                          -1.610345   \n",
       "2068420                     106.0  ...                          -1.610345   \n",
       "2068421                       NaN  ...                           0.374736   \n",
       "2068422                       NaN  ...                           1.043623   \n",
       "2068423                       NaN  ...                          -1.610345   \n",
       "\n",
       "         knn_product_cluster_stability_min knn_product_cluster_stability_std  \\\n",
       "0                                -1.610345                          0.000000   \n",
       "1                                -1.610345                          0.000000   \n",
       "2                                -1.610345                          0.000000   \n",
       "3                                -1.610345                          0.000000   \n",
       "4                                -1.610345                          0.000000   \n",
       "...                                    ...                               ...   \n",
       "2068419                          -1.610345                          0.000000   \n",
       "2068420                          -1.610345                          0.000000   \n",
       "2068421                           0.303841                          0.026850   \n",
       "2068422                           0.825891                          0.070319   \n",
       "2068423                          -1.610345                          0.000000   \n",
       "\n",
       "        knn_product_cluster_stability_median  \\\n",
       "0                                  -1.610345   \n",
       "1                                  -1.610345   \n",
       "2                                  -1.610345   \n",
       "3                                  -1.610345   \n",
       "4                                  -1.610345   \n",
       "...                                      ...   \n",
       "2068419                            -1.610345   \n",
       "2068420                            -1.610345   \n",
       "2068421                             0.336562   \n",
       "2068422                             0.920634   \n",
       "2068423                            -1.610345   \n",
       "\n",
       "         knn_product_cluster_stability_sum  \\\n",
       "0                                -8.051726   \n",
       "1                                -8.051726   \n",
       "2                                -8.051726   \n",
       "3                                -8.051726   \n",
       "4                                -8.051726   \n",
       "...                                    ...   \n",
       "2068419                          -8.051726   \n",
       "2068420                          -8.051726   \n",
       "2068421                           1.726437   \n",
       "2068422                           4.667326   \n",
       "2068423                          -8.051726   \n",
       "\n",
       "         knn_product_cluster_stability_range  \\\n",
       "0                                   0.000000   \n",
       "1                                   0.000000   \n",
       "2                                   0.000000   \n",
       "3                                   0.000000   \n",
       "4                                   0.000000   \n",
       "...                                      ...   \n",
       "2068419                             0.000000   \n",
       "2068420                             0.000000   \n",
       "2068421                             0.070896   \n",
       "2068422                             0.217731   \n",
       "2068423                             0.000000   \n",
       "\n",
       "         knn_product_cluster_stability_weighted_mean catboost_predict  \\\n",
       "0                                          -1.610345         0.186936   \n",
       "1                                          -1.610345         0.770885   \n",
       "2                                          -1.610345         0.224634   \n",
       "3                                          -1.610345         0.234096   \n",
       "4                                          -1.610345         0.579569   \n",
       "...                                              ...              ...   \n",
       "2068419                                    -1.610345         0.226818   \n",
       "2068420                                    -1.610345         0.181089   \n",
       "2068421                                     0.336573         0.585023   \n",
       "2068422                                     0.920638         0.577050   \n",
       "2068423                                    -1.610345         0.523044   \n",
       "\n",
       "        lgb_predict   predict  \n",
       "0          0.177770  0.182353  \n",
       "1          0.812942  0.791914  \n",
       "2          0.213430  0.219032  \n",
       "3          0.222648  0.228372  \n",
       "4          0.615995  0.597782  \n",
       "...             ...       ...  \n",
       "2068419    0.199867  0.213342  \n",
       "2068420    0.152042  0.166566  \n",
       "2068421    0.545881  0.565452  \n",
       "2068422    0.574712  0.575881  \n",
       "2068423    0.527067  0.525056  \n",
       "\n",
       "[2068424 rows x 144 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6f8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263e843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df_pd['catboost_predict'] = catboost_model.predict_proba(test_df_pd[cols])[:, 1]\n",
    "#test_df_pd['lgb_predict'] = lgb_model.predict_proba(test_df_pd[cols])[:, 1]\n",
    "\n",
    "#test_df_pd['predict'] = model.predict(test_df_pd[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc37c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df_pd['predict'] = test_df_pd[['catboost_predict', 'lgb_predict']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74826201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>catboost_predict</th>\n",
       "      <th>lgb_predict</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1342</td>\n",
       "      <td>0.181451</td>\n",
       "      <td>0.173619</td>\n",
       "      <td>0.177535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9852</td>\n",
       "      <td>0.750567</td>\n",
       "      <td>0.793359</td>\n",
       "      <td>0.771963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10206</td>\n",
       "      <td>0.218191</td>\n",
       "      <td>0.218267</td>\n",
       "      <td>0.218229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11317</td>\n",
       "      <td>0.217211</td>\n",
       "      <td>0.226266</td>\n",
       "      <td>0.221738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13289</td>\n",
       "      <td>0.583897</td>\n",
       "      <td>0.610079</td>\n",
       "      <td>0.596988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068419</th>\n",
       "      <td>11157283</td>\n",
       "      <td>0.205491</td>\n",
       "      <td>0.191326</td>\n",
       "      <td>0.198408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068420</th>\n",
       "      <td>11160395</td>\n",
       "      <td>0.170746</td>\n",
       "      <td>0.144183</td>\n",
       "      <td>0.157464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068421</th>\n",
       "      <td>11165052</td>\n",
       "      <td>0.622734</td>\n",
       "      <td>0.654733</td>\n",
       "      <td>0.638733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068422</th>\n",
       "      <td>11168218</td>\n",
       "      <td>0.573673</td>\n",
       "      <td>0.531214</td>\n",
       "      <td>0.552443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068423</th>\n",
       "      <td>11172313</td>\n",
       "      <td>0.534501</td>\n",
       "      <td>0.517988</td>\n",
       "      <td>0.526245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2068424 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  catboost_predict  lgb_predict   predict\n",
       "0            1342          0.181451     0.173619  0.177535\n",
       "1            9852          0.750567     0.793359  0.771963\n",
       "2           10206          0.218191     0.218267  0.218229\n",
       "3           11317          0.217211     0.226266  0.221738\n",
       "4           13289          0.583897     0.610079  0.596988\n",
       "...           ...               ...          ...       ...\n",
       "2068419  11157283          0.205491     0.191326  0.198408\n",
       "2068420  11160395          0.170746     0.144183  0.157464\n",
       "2068421  11165052          0.622734     0.654733  0.638733\n",
       "2068422  11168218          0.573673     0.531214  0.552443\n",
       "2068423  11172313          0.534501     0.517988  0.526245\n",
       "\n",
       "[2068424 rows x 4 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_pd[['user_id', 'catboost_predict', 'lgb_predict', 'predict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "07d338b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_pd[['user_id', 'predict']].to_csv('full_bagging_cat_and_lgb_mean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df6299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd8845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9713219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b4ab1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19490b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1849f6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
