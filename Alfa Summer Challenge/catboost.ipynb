{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5519f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tran_pd = pd.read_parquet(\"data/df_transaction.pa\")\n",
    "tr_pd = pd.read_parquet(\"data/train.pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac604198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39138</th>\n",
       "      <td>109127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39139</th>\n",
       "      <td>109128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39140</th>\n",
       "      <td>109130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39141</th>\n",
       "      <td>109137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39142</th>\n",
       "      <td>109140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39143 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       client_num\n",
       "0               0\n",
       "1              10\n",
       "2              11\n",
       "3              14\n",
       "4              16\n",
       "...           ...\n",
       "39138      109127\n",
       "39139      109128\n",
       "39140      109130\n",
       "39141      109137\n",
       "39142      109140\n",
       "\n",
       "[39143 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids = set(tr_pd['client_num'].unique())\n",
    "all_ids = set(tran_pd['client_num'].unique())\n",
    "\n",
    "test_ids = all_ids - train_ids\n",
    "\n",
    "tran_pd[\"is_train\"] = tran_pd[\"client_num\"].isin(train_ids)\n",
    "\n",
    "tst_pd = pd.DataFrame()\n",
    "tst_pd['client_num'] = list(test_ids)\n",
    "tst_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "625f9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# –ï—Å–ª–∏ –Ω—É–∂–Ω–æ: –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫—É –≤ datetime\n",
    "# tran_pd[\"date_time\"] = pd.to_datetime(tran_pd[\"date_time\"])\n",
    "\n",
    "# –î–µ–Ω—å –Ω–µ–¥–µ–ª–∏ (0=–ü–Ω, 6=–í—Å)\n",
    "tran_pd[\"weekday\"] = tran_pd[\"date_time\"].dt.weekday\n",
    "\n",
    "# –Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ –≤—ã—Ö–æ–¥–Ω—ã–º (–°–±=5, –í—Å=6)\n",
    "tran_pd[\"is_weekend\"] = tran_pd[\"weekday\"].isin([5, 6])\n",
    "\n",
    "# –ß–∞—Å—Ç—å —Å—É—Ç–æ–∫ (—É—Ç—Ä–æ/–¥–µ–Ω—å/–≤–µ—á–µ—Ä/–Ω–æ—á—å)\n",
    "def get_time_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return \"morning\"\n",
    "    elif 12 <= hour < 17:\n",
    "        return \"day\"\n",
    "    elif 17 <= hour < 22:\n",
    "        return \"evening\"\n",
    "    else:\n",
    "        return \"night\"\n",
    "\n",
    "tran_pd[\"hour\"] = tran_pd[\"date_time\"].dt.hour\n",
    "tran_pd[\"time_of_day\"] = tran_pd[\"hour\"].apply(get_time_of_day)\n",
    "\n",
    "# –î–µ–Ω—å –º–µ—Å—è—Ü–∞ –∏ —á–∞—Å—Ç—å –º–µ—Å—è—Ü–∞\n",
    "tran_pd[\"month_day\"] = tran_pd[\"date_time\"].dt.day\n",
    "tran_pd[\"month\"] = tran_pd[\"date_time\"].dt.month\n",
    "tran_pd[\"part_of_month\"] = pd.cut(tran_pd[\"month_day\"], bins=[0, 10, 20, 31], labels=[\"early\", \"middle\", \"late\"])\n",
    "\n",
    "# –§–ª–∞–≥ –º–µ—Å—è—Ü–∞\n",
    "tran_pd[\"is_july\"] = tran_pd[\"month\"] == 7\n",
    "tran_pd[\"is_august\"] = tran_pd[\"month\"] == 8\n",
    "tran_pd[\"is_september\"] = tran_pd[\"month\"] == 9\n",
    "tran_pd[\"is_october\"] = tran_pd[\"month\"] == 10\n",
    "\n",
    "\n",
    "holidays = pd.to_datetime([\n",
    "    \"2024-07-01\", \"2024-07-02\",  # –≤—ã—Ö–æ–¥–Ω—ã–µ\n",
    "    \"2024-08-22\",                # –î–µ–Ω—å —Ñ–ª–∞–≥–∞ –†–æ—Å—Å–∏–∏\n",
    "    \"2024-09-01\",                # –î–µ–Ω—å –∑–Ω–∞–Ω–∏–π\n",
    "    \"2024-10-04\"                 # –î–µ–Ω—å –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–π –æ–±–æ—Ä–æ–Ω—ã\n",
    "])\n",
    "\n",
    "tran_pd[\"is_holiday\"] = tran_pd[\"date_time\"].dt.normalize().isin(holidays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73dbda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ mcc_code ‚Äî —Å—Ç—Ä–æ–∫–∞\n",
    "tran_pd[\"mcc_code\"] = tran_pd[\"mcc_code\"].astype(str).str.zfill(4)\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ü–∏—Ñ—Ä—ã\n",
    "for i in range(4):\n",
    "    tran_pd[f\"mcc_digit_{i}\"] = tran_pd[\"mcc_code\"].str[i].astype(int)\n",
    "\n",
    "# –°–∫–æ–ª—å–∑—è—â–∏–µ –ø–∞—Ä—ã\n",
    "tran_pd[\"mcc_pair_01\"] = tran_pd[\"mcc_code\"].str.slice(0, 2)\n",
    "tran_pd[\"mcc_pair_12\"] = tran_pd[\"mcc_code\"].str.slice(1, 3)\n",
    "tran_pd[\"mcc_pair_23\"] = tran_pd[\"mcc_code\"].str.slice(2, 4)\n",
    "\n",
    "# –°–∫–æ–ª—å–∑—è—â–∏–µ —Ç—Ä–æ–π–∫–∏\n",
    "tran_pd[\"mcc_triplet_012\"] = tran_pd[\"mcc_code\"].str.slice(0, 3)\n",
    "tran_pd[\"mcc_triplet_123\"] = tran_pd[\"mcc_code\"].str.slice(1, 4)\n",
    "\n",
    "\n",
    "# –ß–∞—Å—Ç–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ merchant_name\n",
    "merchant_freq = tran_pd[\"merchant_name\"].value_counts()\n",
    "tran_pd[\"merchant_freq\"] = tran_pd[\"merchant_name\"].map(merchant_freq)\n",
    "\n",
    "# –§–ª–∞–≥ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏\n",
    "# –ü—Ä–æ–¥–∞–≤—Ü—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –±–æ–ª—å—à–µ N —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π ‚Äî –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ\n",
    "POPULAR_THRESHOLD = 500\n",
    "tran_pd[\"is_popular_merchant\"] = tran_pd[\"merchant_freq\"] > POPULAR_THRESHOLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "403cbd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤\n",
    "tran_pd = tran_pd[tran_pd[\"amount\"].notna()]\n",
    "\n",
    "# 2. –í—ã—á–∏—Å–ª–∏–º –≥—Ä–∞–Ω–∏—Ü—ã —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã—Ö –ø–æ —à–∏—Ä–∏–Ω–µ –±–∏–Ω–æ–≤\n",
    "amount_bins = np.linspace(tran_pd[\"amount\"].min(), tran_pd[\"amount\"].max(), 11)\n",
    "\n",
    "# 3. –ü—Ä–∏—Å–≤–æ–∏–º –∫–∞–∂–¥–æ–º—É amount –µ–≥–æ –±–∏–Ω (–æ—Ç 0 –¥–æ 9)\n",
    "tran_pd[\"amount_bin\"] = np.digitize(tran_pd[\"amount\"], bins=amount_bins[1:-1], right=True)\n",
    "\n",
    "# 4. One-hot encoding\n",
    "amount_bin_dummies = pd.get_dummies(tran_pd[\"amount_bin\"], prefix=\"amount_bin\")\n",
    "\n",
    "# 5. –î–æ–±–∞–≤–∏–º –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "tran_pd = pd.concat([tran_pd, amount_bin_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939722db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞\n",
    "tran_pd = tran_pd.sort_values([\"client_num\", \"date_time\"])\n",
    "\n",
    "# –°–∫–æ–ª—å–∑—è—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "tran_pd[\"rolling_mean_7\"] = (\n",
    "    tran_pd.groupby(\"client_num\")[\"amount\"]\n",
    "    .transform(lambda x: x.rolling(window=7, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "tran_pd[\"rolling_std_7\"] = (\n",
    "    tran_pd.groupby(\"client_num\")[\"amount\"]\n",
    "    .transform(lambda x: x.rolling(window=7, min_periods=1).std().fillna(0))\n",
    ")\n",
    "\n",
    "tran_pd[\"rolling_mean_30\"] = (\n",
    "    tran_pd.groupby(\"client_num\")[\"amount\"]\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "tran_pd[\"rolling_std_30\"] = (\n",
    "    tran_pd.groupby(\"client_num\")[\"amount\"]\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).std().fillna(0))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47145a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_pd[\"week\"] = tran_pd[\"date_time\"].dt.isocalendar().week\n",
    "\n",
    "weekly_counts = tran_pd.groupby([\"client_num\", \"week\"]).size().reset_index(name=\"weekly_txn_count\")\n",
    "weekly_stats = weekly_counts.groupby(\"client_num\")[\"weekly_txn_count\"].agg(\n",
    "    mean_weekly_txn=\"mean\",\n",
    "    std_weekly_txn=\"std\",\n",
    "    max_weekly_txn=\"max\"\n",
    ")\n",
    "\n",
    "max_date = tran_pd[\"date_time\"].max()\n",
    "\n",
    "last_activity = tran_pd.groupby(\"client_num\")[\"date_time\"].max().reset_index()\n",
    "last_activity[\"days_since_last_txn\"] = (max_date - last_activity[\"date_time\"]).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26c7fd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_1072\\3187096839.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  trend_by_client = monthly_amount.groupby(\"client_num\").apply(compute_trend).reset_index()\n"
     ]
    }
   ],
   "source": [
    "tran_pd[\"year_month\"] = tran_pd[\"date_time\"].dt.to_period(\"M\")\n",
    "\n",
    "# –°—Ä–µ–¥–Ω–µ–µ –ø–æ –º–µ—Å—è—Ü–∞–º\n",
    "monthly_amount = tran_pd.groupby([\"client_num\", \"year_month\"])[\"amount\"].mean().reset_index()\n",
    "\n",
    "# –î–ª—è –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞ ‚Äî –ø–µ—Ä–µ–≤–µ–¥–µ–º –º–µ—Å—è—Ü—ã –≤ —á–∏—Å–ª–æ–≤—É—é —Ñ–æ—Ä–º—É\n",
    "monthly_amount[\"month_num\"] = monthly_amount[\"year_month\"].apply(lambda x: x.ordinal)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def compute_trend(df):\n",
    "    if len(df) < 2:\n",
    "        return 0\n",
    "    X = df[\"month_num\"].values.reshape(-1, 1)\n",
    "    y = df[\"amount\"].values\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model.coef_[0]\n",
    "\n",
    "trend_by_client = monthly_amount.groupby(\"client_num\").apply(compute_trend).reset_index()\n",
    "trend_by_client.columns = [\"client_num\", \"amount_trend\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c5f7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_1072\\583726197.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top_cat = tran_pd.groupby(\"client_num\").apply(extract_top_features).reset_index()\n"
     ]
    }
   ],
   "source": [
    "def top_n(series, n):\n",
    "    vc = series.value_counts()\n",
    "    top = vc.index[:n]\n",
    "    return pd.Series({f\"top_{i+1}\": top[i] if i < len(top) else None for i in range(n)})\n",
    "\n",
    "def extract_top_features(group):\n",
    "    result = {}\n",
    "    result.update(top_n(group[\"mcc_code\"], 2).rename(lambda x: x.replace(\"top_\", \"top_mcc_\")))\n",
    "    result.update(top_n(group[\"merchant_name\"], 2).rename(lambda x: x.replace(\"top_\", \"top_merchant_\")))\n",
    "    result.update(top_n(group[\"time_of_day\"], 2).rename(lambda x: x.replace(\"top_\", \"top_tod_\")))\n",
    "    return pd.Series(result)\n",
    "\n",
    "top_cat = tran_pd.groupby(\"client_num\").apply(extract_top_features).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69f80edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_num</th>\n",
       "      <th>target</th>\n",
       "      <th>count_amount</th>\n",
       "      <th>avg_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>std_amount</th>\n",
       "      <th>min_amount</th>\n",
       "      <th>max_amount</th>\n",
       "      <th>unique_mccs</th>\n",
       "      <th>first_txn</th>\n",
       "      <th>last_txn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>3599.491667</td>\n",
       "      <td>863878</td>\n",
       "      <td>11704.843812</td>\n",
       "      <td>6</td>\n",
       "      <td>100000</td>\n",
       "      <td>29</td>\n",
       "      <td>2024-07-01 09:01:00</td>\n",
       "      <td>2024-09-30 17:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>1147.026667</td>\n",
       "      <td>344108</td>\n",
       "      <td>2629.178018</td>\n",
       "      <td>23</td>\n",
       "      <td>24496</td>\n",
       "      <td>33</td>\n",
       "      <td>2024-07-01 16:52:00</td>\n",
       "      <td>2024-09-30 19:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>147</td>\n",
       "      <td>11032.823129</td>\n",
       "      <td>1621825</td>\n",
       "      <td>86498.559476</td>\n",
       "      <td>1</td>\n",
       "      <td>1000000</td>\n",
       "      <td>21</td>\n",
       "      <td>2024-07-01 08:08:00</td>\n",
       "      <td>2024-09-30 21:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>122</td>\n",
       "      <td>1637.672131</td>\n",
       "      <td>199796</td>\n",
       "      <td>4938.356295</td>\n",
       "      <td>24</td>\n",
       "      <td>50000</td>\n",
       "      <td>9</td>\n",
       "      <td>2024-07-02 10:45:00</td>\n",
       "      <td>2024-09-30 20:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>391.622093</td>\n",
       "      <td>67359</td>\n",
       "      <td>1183.405909</td>\n",
       "      <td>22</td>\n",
       "      <td>10000</td>\n",
       "      <td>18</td>\n",
       "      <td>2024-07-01 02:07:00</td>\n",
       "      <td>2024-09-28 06:23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>109136</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1291.800000</td>\n",
       "      <td>19377</td>\n",
       "      <td>1875.628588</td>\n",
       "      <td>55</td>\n",
       "      <td>5190</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-07-04 18:10:00</td>\n",
       "      <td>2024-08-08 15:11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>109138</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>14767.687500</td>\n",
       "      <td>236283</td>\n",
       "      <td>20613.075561</td>\n",
       "      <td>1</td>\n",
       "      <td>59255</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-08-14 10:49:00</td>\n",
       "      <td>2024-09-30 08:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>109139</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>642.666667</td>\n",
       "      <td>9640</td>\n",
       "      <td>344.028169</td>\n",
       "      <td>25</td>\n",
       "      <td>1150</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-07-30 14:48:00</td>\n",
       "      <td>2024-08-16 12:16:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>109141</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3865.187500</td>\n",
       "      <td>61843</td>\n",
       "      <td>7251.421398</td>\n",
       "      <td>170</td>\n",
       "      <td>22360</td>\n",
       "      <td>10</td>\n",
       "      <td>2024-07-08 10:23:00</td>\n",
       "      <td>2024-09-02 18:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>109142</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>22740.000000</td>\n",
       "      <td>341100</td>\n",
       "      <td>19589.348418</td>\n",
       "      <td>100</td>\n",
       "      <td>86000</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-08-16 15:47:00</td>\n",
       "      <td>2024-08-19 22:12:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       client_num  target  count_amount    avg_amount  total_amount  \\\n",
       "0               1       4           240   3599.491667        863878   \n",
       "1               2       5           300   1147.026667        344108   \n",
       "2               3       3           147  11032.823129       1621825   \n",
       "3               4       5           122   1637.672131        199796   \n",
       "4               5       2           172    391.622093         67359   \n",
       "...           ...     ...           ...           ...           ...   \n",
       "69995      109136       3            15   1291.800000         19377   \n",
       "69996      109138       2            16  14767.687500        236283   \n",
       "69997      109139       0            15    642.666667          9640   \n",
       "69998      109141       0            16   3865.187500         61843   \n",
       "69999      109142       0            15  22740.000000        341100   \n",
       "\n",
       "         std_amount  min_amount  max_amount  unique_mccs           first_txn  \\\n",
       "0      11704.843812           6      100000           29 2024-07-01 09:01:00   \n",
       "1       2629.178018          23       24496           33 2024-07-01 16:52:00   \n",
       "2      86498.559476           1     1000000           21 2024-07-01 08:08:00   \n",
       "3       4938.356295          24       50000            9 2024-07-02 10:45:00   \n",
       "4       1183.405909          22       10000           18 2024-07-01 02:07:00   \n",
       "...             ...         ...         ...          ...                 ...   \n",
       "69995   1875.628588          55        5190            6 2024-07-04 18:10:00   \n",
       "69996  20613.075561           1       59255            4 2024-08-14 10:49:00   \n",
       "69997    344.028169          25        1150            6 2024-07-30 14:48:00   \n",
       "69998   7251.421398         170       22360           10 2024-07-08 10:23:00   \n",
       "69999  19589.348418         100       86000            1 2024-08-16 15:47:00   \n",
       "\n",
       "                 last_txn  \n",
       "0     2024-09-30 17:55:00  \n",
       "1     2024-09-30 19:36:00  \n",
       "2     2024-09-30 21:56:00  \n",
       "3     2024-09-30 20:34:00  \n",
       "4     2024-09-28 06:23:00  \n",
       "...                   ...  \n",
       "69995 2024-08-08 15:11:00  \n",
       "69996 2024-09-30 08:38:00  \n",
       "69997 2024-08-16 12:16:00  \n",
       "69998 2024-09-02 18:06:00  \n",
       "69999 2024-08-19 22:12:00  \n",
       "\n",
       "[70000 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ß–∏—Å–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ—Ä–≥–æ–≤—Ü–µ–≤\n",
    "tran_pd[\"merchant_name\"] = tran_pd[\"merchant_name\"].astype(str)  # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π\n",
    "agg_merchant = tran_pd.groupby(\"client_num\").agg(\n",
    "    unique_merchants=('merchant_name', pd.Series.nunique),\n",
    "    mean_merchant_freq=('merchant_freq', 'mean'),\n",
    "    max_merchant_freq=('merchant_freq', 'max'),\n",
    "    popular_merchant_rate=('is_popular_merchant', 'mean')\n",
    ")\n",
    "\n",
    "# –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "agg_time = tran_pd.groupby(\"client_num\").agg(\n",
    "    weekend_rate=('is_weekend', 'mean'),\n",
    "    holiday_rate=('is_holiday', 'mean')\n",
    ")\n",
    "\n",
    "# –ß–∞—Å—Ç–∏ —Å—É—Ç–æ–∫ (one-hot encode –∏ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ)\n",
    "time_of_day_dummies = pd.get_dummies(tran_pd[\"time_of_day\"], prefix=\"tod\")\n",
    "tran_pd = pd.concat([tran_pd, time_of_day_dummies], axis=1)\n",
    "\n",
    "agg_tod = tran_pd.groupby(\"client_num\")[time_of_day_dummies.columns].mean()\n",
    "\n",
    "\n",
    "# –ö–æ–ª-–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π MCC\n",
    "agg_mcc = tran_pd.groupby(\"client_num\").agg(\n",
    "    unique_mcc_pairs=('mcc_pair_01', pd.Series.nunique),\n",
    "    unique_mcc_triplets=('mcc_triplet_012', pd.Series.nunique)\n",
    ")\n",
    "\n",
    "# Binned amount (one-hot), —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –∫–∞–∂–¥–æ–º—É bin\n",
    "amount_bin_cols = [col for col in tran_pd.columns if col.startswith(\"amount_bin_\")]\n",
    "agg_amount_bins = tran_pd.groupby(\"client_num\")[amount_bin_cols].mean()\n",
    "\n",
    "\n",
    "client_features = (\n",
    "    tran_pd.groupby(\"client_num\")\n",
    "    .agg(\n",
    "        count_amount=('amount', 'count'),\n",
    "        avg_amount=('amount', 'mean'),\n",
    "        total_amount=('amount', 'sum'),\n",
    "        std_amount=('amount', 'std'),\n",
    "        min_amount=('amount', 'min'),\n",
    "        max_amount=('amount', 'max'),\n",
    "        unique_mccs=('mcc_code', pd.Series.nunique),\n",
    "        first_txn=('date_time', 'min'),\n",
    "        last_txn=('date_time', 'max')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "client_features_ext = (\n",
    "    client_features\n",
    "    .merge(agg_merchant, on=\"client_num\", how=\"left\")\n",
    "    .merge(agg_time, on=\"client_num\", how=\"left\")\n",
    "    .merge(agg_tod, on=\"client_num\", how=\"left\")\n",
    "    .merge(agg_mcc, on=\"client_num\", how=\"left\")\n",
    "    .merge(agg_amount_bins, on=\"client_num\", how=\"left\")\n",
    ")\n",
    "\n",
    "tr_features = tr_pd.merge(client_features, on=\"client_num\", how=\"left\")\n",
    "tst_features = tst_pd.merge(client_features, on=\"client_num\", how=\"left\")\n",
    "\n",
    "tr_features = tr_features.sort_values(\"client_num\").reset_index(drop=True)\n",
    "tst_features = tst_features.sort_values(\"client_num\").reset_index(drop=True)\n",
    "\n",
    "tr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "709fb576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_repetition_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # –ò–Ω—Ç–µ—Ä–≤–∞–ª—ã –º–µ–∂–¥—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏ (–≤ –¥–Ω—è—Ö)\n",
    "    df[\"txn_diff_days\"] = (\n",
    "        df.sort_values([\"client_num\", \"date_time\"])\n",
    "        .groupby(\"client_num\")[\"date_time\"]\n",
    "        .diff().dt.total_seconds().div(86400)\n",
    "    )\n",
    "\n",
    "    # –°—Ä–µ–¥–Ω–∏–π –∏ STD –∏–Ω—Ç–µ—Ä–≤–∞–ª\n",
    "    agg_intervals = df.groupby(\"client_num\")[\"txn_diff_days\"].agg(\n",
    "        mean_interval_days=\"mean\",\n",
    "        std_interval_days=\"std\"\n",
    "    ).reset_index()\n",
    "\n",
    "    return agg_intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcdf257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_outlier_behavior(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # –û—Ç–º–µ—Ç–∏–º –≤—ã–±—Ä–æ—Å—ã –ø–æ amount (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –∫–ª–∏–µ–Ω—Ç–∞)\n",
    "    df[\"amount_z\"] = (\n",
    "        df.groupby(\"client_num\")[\"amount\"]\n",
    "        .transform(lambda x: (x - x.mean()) / x.std(ddof=0))\n",
    "    )\n",
    "\n",
    "    df[\"is_amount_outlier\"] = df[\"amount_z\"].abs() > 3\n",
    "\n",
    "    # –î–æ–ª—è –≤—ã–±—Ä–æ—Å–æ–≤ –ø–æ amount\n",
    "    outlier_ratio = df.groupby(\"client_num\")[\"is_amount_outlier\"].mean().reset_index()\n",
    "    outlier_ratio.columns = [\"client_num\", \"amount_outlier_ratio\"]\n",
    "\n",
    "    return outlier_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3dfe4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entropy_features(df):\n",
    "    from scipy.stats import entropy\n",
    "    df = df.copy()\n",
    "\n",
    "    def calc_entropy(series):\n",
    "        probs = series.value_counts(normalize=True)\n",
    "        return entropy(probs)\n",
    "\n",
    "    entropies = df.groupby(\"client_num\").agg(\n",
    "        mcc_entropy=(\"mcc_code\", calc_entropy),\n",
    "        merchant_entropy=(\"merchant_name\", calc_entropy),\n",
    "        tod_entropy=(\"time_of_day\", calc_entropy)\n",
    "    ).reset_index()\n",
    "\n",
    "    return entropies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09555e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_recent_activity(df, days=14):\n",
    "    df = df.copy()\n",
    "\n",
    "    max_date = df[\"date_time\"].max()\n",
    "    recent_cutoff = max_date - pd.Timedelta(days=days)\n",
    "\n",
    "    recent_df = df[df[\"date_time\"] >= recent_cutoff]\n",
    "\n",
    "    recent_agg = recent_df.groupby(\"client_num\").agg(\n",
    "        recent_txn_count=(\"amount\", \"count\"),\n",
    "        recent_amount_mean=(\"amount\", \"mean\"),\n",
    "        recent_amount_std=(\"amount\", \"std\")\n",
    "    ).reset_index()\n",
    "\n",
    "    return recent_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aa28e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mcc_group_flags(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # –ü—Ä–∏–º–µ—Ä: MCC –∫–æ–¥—ã —Å—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç–æ–≤, —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞, –∏ —Ç.–ø.\n",
    "    RETAIL_MCC = {\"5411\", \"5311\", \"5541\"}  # grocery, department store, gas\n",
    "    TRANSPORT_MCC = {\"4111\", \"4121\", \"4789\"}\n",
    "    ECOMM_MCC = {\"5964\", \"5815\", \"5816\"}\n",
    "\n",
    "    df[\"is_retail\"] = df[\"mcc_code\"].isin(RETAIL_MCC)\n",
    "    df[\"is_transport\"] = df[\"mcc_code\"].isin(TRANSPORT_MCC)\n",
    "    df[\"is_ecomm\"] = df[\"mcc_code\"].isin(ECOMM_MCC)\n",
    "\n",
    "    mcc_flags = df.groupby(\"client_num\").agg(\n",
    "        retail_ratio=(\"is_retail\", \"mean\"),\n",
    "        transport_ratio=(\"is_transport\", \"mean\"),\n",
    "        ecomm_ratio=(\"is_ecomm\", \"mean\")\n",
    "    ).reset_index()\n",
    "\n",
    "    return mcc_flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3492754",
   "metadata": {},
   "outputs": [],
   "source": [
    "repetition_features = add_repetition_features(tran_pd)\n",
    "outlier_behavior = add_outlier_behavior(tran_pd)\n",
    "entropy_features = add_entropy_features(tran_pd)\n",
    "recent_activity = add_recent_activity(tran_pd)\n",
    "mcc_group_flags = add_mcc_group_flags(tran_pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38c87cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í—Ä–µ–º—è –º–µ–∂–¥—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏\n",
    "tran_pd = tran_pd.sort_values([\"client_num\", \"date_time\"])\n",
    "tran_pd[\"txn_diff\"] = tran_pd.groupby(\"client_num\")[\"date_time\"].diff().dt.total_seconds()\n",
    "\n",
    "periodicity_stats = tran_pd.groupby(\"client_num\")[\"txn_diff\"].agg(\n",
    "    mean_txn_diff=\"mean\",\n",
    "    std_txn_diff=\"std\",\n",
    "    min_txn_diff=\"min\",\n",
    "    max_txn_diff=\"max\"\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "diversity_features = tran_pd.groupby(\"client_num\").agg(\n",
    "    mcc_entropy=('mcc_code', lambda x: -np.sum((x.value_counts(normalize=True) * np.log2(x.value_counts(normalize=True) + 1e-9)))),\n",
    "    merchant_entropy=('merchant_name', lambda x: -np.sum((x.value_counts(normalize=True) * np.log2(x.value_counts(normalize=True) + 1e-9))))\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# –ß–∞—Å–æ–≤–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å\n",
    "hourly_activity = tran_pd.groupby(\"client_num\")[\"hour\"].agg(\n",
    "    mean_hour=\"mean\",\n",
    "    std_hour=\"std\"\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "from scipy.stats import skew\n",
    "\n",
    "amount_stats_extra = tran_pd.groupby(\"client_num\")[\"amount\"].agg(\n",
    "    amount_skew=\"skew\",\n",
    "    amount_median=\"median\",\n",
    "    amount_q25=lambda x: np.percentile(x, 25),\n",
    "    amount_q75=lambda x: np.percentile(x, 75),\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# –î–æ–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ MCC\n",
    "mcc_mode = tran_pd.groupby(\"client_num\")[\"mcc_code\"].agg(lambda x: x.value_counts(normalize=True).iloc[0])\n",
    "mcc_mode.name = \"top_mcc_share\"\n",
    "\n",
    "# –¢–æ –∂–µ –¥–ª—è —Ç–æ—Ä–≥–æ–≤—Ü–µ–≤\n",
    "merchant_mode = tran_pd.groupby(\"client_num\")[\"merchant_name\"].agg(lambda x: x.value_counts(normalize=True).iloc[0])\n",
    "merchant_mode.name = \"top_merchant_share\"\n",
    "\n",
    "habit_features = pd.concat([mcc_mode, merchant_mode], axis=1).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e23d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_features_final = (\n",
    "    client_features_ext\n",
    "    .merge(weekly_stats, on=\"client_num\", how=\"left\")\n",
    "    .merge(last_activity[[\"client_num\", \"days_since_last_txn\"]], on=\"client_num\", how=\"left\")\n",
    "    .merge(trend_by_client, on=\"client_num\", how=\"left\")\n",
    "    .merge(top_cat, on=\"client_num\", how=\"left\")\n",
    "\n",
    "    .merge(periodicity_stats, on=\"client_num\", how=\"left\")\n",
    "    .merge(diversity_features, on=\"client_num\", how=\"left\")\n",
    "    .merge(hourly_activity, on=\"client_num\", how=\"left\")\n",
    "    .merge(amount_stats_extra, on=\"client_num\", how=\"left\")\n",
    "    .merge(habit_features, on=\"client_num\", how=\"left\")\n",
    "\n",
    "    #.merge(repetition_features, on=\"client_num\", how=\"left\")\n",
    "    #.merge(outlier_behavior, on=\"client_num\", how=\"left\")\n",
    "    #.merge(entropy_features, on=\"client_num\", how=\"left\")\n",
    "    #.merge(recent_activity, on=\"client_num\", how=\"left\")\n",
    "    #.merge(mcc_group_flags, on=\"client_num\", how=\"left\")\n",
    ")\n",
    "\n",
    "tr_features = tr_pd.merge(client_features_final, on=\"client_num\", how=\"left\")\n",
    "tst_features = tst_pd.merge(client_features_final, on=\"client_num\", how=\"left\")\n",
    "\n",
    "tr_features = tr_features.sort_values(\"client_num\").reset_index(drop=True)\n",
    "tst_features = tst_features.sort_values(\"client_num\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c042362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_lgbm(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
    "    datetime_cols = df.select_dtypes(include=[\"datetime64\"]).columns\n",
    "    for col in datetime_cols:\n",
    "        min_time = df[col].min()\n",
    "        df[col] = (df[col] - min_time).dt.total_seconds()\n",
    "\n",
    "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ object –∫–æ–ª–æ–Ω–æ–∫ ‚Äî –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —Å—Ç—Ä–æ–∫–µ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)\n",
    "    object_cols = ['top_mcc_1', 'top_mcc_2', 'top_merchant_1', 'top_merchant_2', 'top_tod_1', 'top_tod_2']\n",
    "    for col in object_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "    return df\n",
    "\n",
    "tr_features = preprocess_for_lgbm(tr_features)\n",
    "tst_features = preprocess_for_lgbm(tst_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d6a8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_features = tr_features.astype(str).fillna('nan')\n",
    "tst_features = tst_features.astype(str).fillna('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb654e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.9268847\ttest: 1.9268061\tbest: 1.9268061 (0)\ttotal: 1.44s\tremaining: 23m 56s\n",
      "100:\tlearn: 1.6718593\ttest: 1.7046219\tbest: 1.7046219 (100)\ttotal: 3m 52s\tremaining: 34m 31s\n",
      "200:\tlearn: 1.6246419\ttest: 1.6907904\tbest: 1.6907904 (200)\ttotal: 7m 48s\tremaining: 31m 4s\n",
      "300:\tlearn: 1.5851882\ttest: 1.6860389\tbest: 1.6859200 (294)\ttotal: 11m 50s\tremaining: 27m 30s\n",
      "400:\tlearn: 1.5541187\ttest: 1.6840896\tbest: 1.6840896 (400)\ttotal: 15m 54s\tremaining: 23m 46s\n",
      "500:\tlearn: 1.5276368\ttest: 1.6829827\tbest: 1.6829827 (500)\ttotal: 19m 58s\tremaining: 19m 53s\n",
      "600:\tlearn: 1.5008051\ttest: 1.6826012\tbest: 1.6825999 (589)\ttotal: 24m 3s\tremaining: 15m 58s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 1.682503274\n",
      "bestIteration = 631\n",
      "\n",
      "Shrink model to first 632 iterations.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m val_preds_class \u001b[38;5;241m=\u001b[39m val_preds_proba\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     72\u001b[0m val_y_np \u001b[38;5;241m=\u001b[39m cat_y_val\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m---> 74\u001b[0m wmae_score \u001b[38;5;241m=\u001b[39m compute_wmae(val_y_np, val_preds_class)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä Validation WMAE (argmax): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwmae_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 44\u001b[0m, in \u001b[0;36mcompute_wmae\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_wmae\u001b[39m(y_true, y_pred):\n\u001b[0;32m     43\u001b[0m     weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvectorize(weights_by_class\u001b[38;5;241m.\u001b[39mget)(y_true)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(weights \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(y_true \u001b[38;5;241m-\u001b[39m y_pred))\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# DATA PREP\n",
    "cat_X = tr_features.drop(columns=[\"target\"])\n",
    "cat_y = tr_features[\"target\"]\n",
    "cat_X_test = tst_features\n",
    "\n",
    "cat_categorical_features = tr_features.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "\n",
    "cat_X_train, cat_X_val, cat_y_train, cat_y_val = train_test_split(\n",
    "    cat_X, cat_y, test_size=0.37, random_state=42, stratify=cat_y\n",
    ")\n",
    "\n",
    "if \"target\" in cat_categorical_features:\n",
    "    cat_categorical_features.remove(\"target\")\n",
    "\n",
    "# PARAMS\n",
    "cat_params = {\n",
    "    \"loss_function\": \"MultiClass\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"depth\": 7,\n",
    "    \"random_seed\": 42,\n",
    "    \"verbose\": 100,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "}\n",
    "\n",
    "weights_by_class = {\n",
    "    0: 1.00,\n",
    "    1: 0.72,\n",
    "    2: 0.52,\n",
    "    3: 0.37,\n",
    "    4: 0.27,\n",
    "    5: 0.19,\n",
    "    6: 0.14,\n",
    "    7: 0.00,\n",
    "}\n",
    "\n",
    "# CUSTOM WMAE\n",
    "def compute_wmae(y_true, y_pred):\n",
    "    weights = np.vectorize(weights_by_class.get)(y_true)\n",
    "    return np.mean(weights * np.abs(y_true - y_pred))\n",
    "\n",
    "def catboost_wmae(y_true, y_pred):\n",
    "    y_true = y_true.get_label().astype(int)\n",
    "    y_pred = y_pred.reshape(-1, 8).argmax(axis=1)\n",
    "    weights = np.vectorize(weights_by_class.get)(y_true)\n",
    "    error = np.mean(weights * np.abs(y_true - y_pred))\n",
    "    return \"wmae\", error, False\n",
    "\n",
    "# DATASET\n",
    "train_pool = cb.Pool(data=cat_X_train, label=cat_y_train, cat_features=cat_categorical_features)\n",
    "val_pool = cb.Pool(data=cat_X_val, label=cat_y_val, cat_features=cat_categorical_features)\n",
    "\n",
    "# TRAIN\n",
    "model = cb.CatBoost(\n",
    "    cat_params\n",
    ")\n",
    "model.fit(\n",
    "    train_pool,\n",
    "    eval_set=val_pool,\n",
    "    metric_period=100,\n",
    "    verbose=100,\n",
    "    early_stopping_rounds=50,\n",
    ")\n",
    "\n",
    "# VALIDATION PREDICTIONS\n",
    "val_preds_proba = model.predict(val_pool, prediction_type=\"Probability\")\n",
    "val_preds_class = val_preds_proba.argmax(axis=1)\n",
    "val_y_np = cat_y_val.to_numpy()\n",
    "val_y_np= val_y_np.astype(int)\n",
    "\n",
    "wmae_score = compute_wmae(val_y_np, val_preds_class)\n",
    "print(f\"\\nüìä Validation WMAE (argmax): {wmae_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17932519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Validation WMAE (argmax): 0.59406\n"
     ]
    }
   ],
   "source": [
    "wmae_score = compute_wmae(val_y_np.astype(int), val_preds_class)\n",
    "print(f\"\\nüìä Validation WMAE (argmax): {wmae_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8c5014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Validation WMAE (thresholded): 0.55462\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CUSTOM THRESHOLDS\n",
    "thresholds = { \n",
    "    0: 0.24, \n",
    "    1: 0.235, \n",
    "    2: 0.122, \n",
    "    3: 0.05, \n",
    "    4: 0.05, \n",
    "    5: 0.05, \n",
    "    6: 0.05, \n",
    "    7: 0.05\n",
    "}\n",
    "\n",
    "def predict_with_thresholds(probas, thresholds):\n",
    "    preds = []\n",
    "    for row in probas:\n",
    "        above_threshold = [i for i, p in enumerate(row) if p >= thresholds[i]]\n",
    "        if not above_threshold:\n",
    "            preds.append(np.argmax(row))\n",
    "        else:\n",
    "            preds.append(max(above_threshold, key=lambda i: row[i] * weights_by_class[i]))\n",
    "    return np.array(preds)\n",
    "\n",
    "val_preds_custom = predict_with_thresholds(val_preds_proba, thresholds)\n",
    "wmae_score_custom = compute_wmae(val_y_np.astype(int), val_preds_custom)\n",
    "print(f\"\\nüìä Validation WMAE (thresholded): {wmae_score_custom:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f6daaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST PREDICTION\n",
    "test_pool = cb.Pool(data=cat_X_test, cat_features=cat_categorical_features)\n",
    "test_preds_proba = model.predict(test_pool, prediction_type=\"Probability\")\n",
    "test_preds_labels = predict_with_thresholds(test_preds_proba, thresholds)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"client_num\": tst_features[\"client_num\"],\n",
    "    \"target\": test_preds_labels\n",
    "})\n",
    "\n",
    "submission.to_csv(\"catboost_ch_th_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "055eb825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º DataFrame —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏\n",
    "df_proba = pd.DataFrame(\n",
    "    test_preds_proba,\n",
    "    columns=[f'class_{i}' for i in range(test_preds_proba.shape[1])]  # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–º–µ–Ω–∞ —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    ")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV\n",
    "df_proba.to_csv('cat_test_preds_proba.csv', index=False)  # index=False —á—Ç–æ–±—ã –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∏–Ω–¥–µ–∫—Å—ã —Å—Ç—Ä–æ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2675ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
